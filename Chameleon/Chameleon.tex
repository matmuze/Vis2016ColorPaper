% ---------------------------------------------------------------------------
% Author guideline and sample document for EG publication using LaTeX2e input
% D.Fellner, v1.12, Nov 01, 2006

\documentclass{egpubl}
\usepackage{vcbm2016}

% --- for  Annual CONFERENCE
% \ConferenceSubmission % uncomment for Conference submission
% \ConferencePaper      % uncomment for (final) Conference Paper
% \STAR                 % uncomment for STAR contribution
% \Tutorial             % uncomment for Tutorial contribution
% \ShortPresentation    % uncomment for (final) Short Conference Presentation
%
% --- for  CGF Journal
% \JournalSubmission    % uncomment for submission to Computer Graphics Forum
% \JournalPaper         % uncomment for final version of Journal Paper
%
% --- for  EG Workshop Proceedings
\WsSubmission    % uncomment for submission to EG Workshop
% \WsPaper         % uncomment for final version of EG Workshop contribution
%
\electronicVersion % can be used both for the printed and electronic version

% !! *please* don't change anything above
% !! unless you REALLY know what you are doing
% ------------------------------------------------------------------------

% for including postscript figures
% mind: package option 'draft' will replace PS figure by a filname within a frame
\ifpdf \usepackage[pdftex]{graphicx} \pdfcompresslevel=9
\else \usepackage[dvips]{graphicx} \fi

\PrintedOrElectronic

% prepare for electronic version of your document
\usepackage{t1enc,dfadobe}

\usepackage{egweblnk}
\usepackage{cite}
\usepackage{amsmath}
\usepackage{booktabs}
% For backwards compatibility to old LaTeX type font selection.
% Uncomment if your document adheres to LaTeX2e recommendations.
% \let\rm=\rmfamily    \let\sf=\sffamily    \let\tt=\ttfamily
% \let\it=\itshape     \let\sl=\slshape     \let\sc=\scshape
% \let\bf=\bfseries

% end of prologue



% ---------------------------------------------------------------------
% EG author guidelines plus sample file for EG publication using LaTeX2e input
% D.Fellner, v1.17, Sep 23, 2010


\title[Chameleon]%
{------------Chameleon------------ \\  Dynamic Color Mapping	for Multi-Scale Structural Biology Models}

% for anonymous conference submission please enter your SUBMISSION ID
% instead of the author's name (and leave the affiliation blank) !!
\author[Waldin et al.]
{Nicholas Waldin$^{1}$, Mathieu Le Muzic$^{1}$, Maneula Waldner$^{1}$, Eduard Gr\"oller$^{1,2}$, David Goodsell$^{3}$, Autin Ludovic$^{3}$, Ivan Viola$^{1}$ 
%	and auth2$^{2}$
	%        S. Spencer$^2$\thanks{Chairman Siggraph Publications Board}
	\\
	% For Computer Graphics Forum: Please use the abbreviation of your first name.
	$^1$TU Wien \\
	$^2$VRVis\\
	$^3$Scripps Research Institute
	%        $^2$ Another Department to illustrate the use in papers from authors
	%             with different affiliations
}

% ------------------------------------------------------------------------

% if the Editors-in-Chief have given you the data, you may uncomment
% the following five lines and insert it here
%
% \volume{27}   % the volume in which the issue will be published;
% \issue{1}     % the issue number of the publication
% \pStartPage{1}      % set starting page


%-------------------------------------------------------------------------
\begin{document}
	
	\teaser{
		\centering
		\includegraphics[width=0.975\linewidth]{Figures/teaser_new}
				\caption{Interactive multi-scale visualization of HIV using ``Chameleon'' for dynamic color coding of protein and atom properties: 
					Zooming from an overview of the entire virus (a) to the capsid (b), the capsid interior (c), a single integrase protein in the capsid (d), and its atomic structure (e). 
					Mind how protein colors become more differentiated as we zoom in (a-b), and how protein domains (c), secondary structures (d), and individual atoms (e) are being progressively revealed through dynamic color adaptations.  }
				
%		\caption{Multi-scale visualization of HIV in real-time, using cellVIEW~\cite{muzic2015cellview} for rendering, together with the presented technique "Chameleon" for dynamic color coding of protein and atom properties.
%			The series of vignettes represent, from left to right, a zooming operation from the entire virus down to single atoms.
%			Along the way, we modulate the colors to provide relevant information based on the current zoom level.
%			(a) At the highest zoom level the orange proteins located inside the capsid are hardly distinguishable, as surrounding compartments which contain more various protein types (green, and purple) are prioritized on the color palette. 
%			(b) As we zoom in on the capsid proteins, other compartments become less visible, which allows the capsid protein ensemble to occupy more space in the color palette.
%			(c) As we continue zooming, we reveal the domains of the protein by shifting the hue value progressively. Simultaneously, we also shift the luminance to show the presence of underlying structures in the next levels.
%			(d) The secondary structures are differentiated by hue, and the atom types by luminance, analogous to the previous levels.
%			At the same time we progressively desaturate the context proteins to reduce the number of colors and improve clarity.
%			(e) The atom colors are progressively shown as we reach the final zoom level.}
		
		\label{teaserImage}
	}
	
	\maketitle
	
	\begin{abstract}
		Visualization of structural biology data uses color to categorize or separate dense structures into particular semantic units. 
		In multiscale models of viruses or bacteria, there are atoms on the finest level of detail, then amino-acids, secondary structures, macromolecules, up to the compartment level and, in all these levels, elements can be visually distinguished by color.
		However, currently only single scale coloring schemes are utilized that show information for one particular scale only. 
		We present a novel technology which adaptively, based on the current scale level, adjusts the color scheme to depict or distinguish the currently best visible structural information. 
		We treat the color as a visual resource that is distributed given a particular demand. 
		The changes of the color scheme are seamlessly interpolated between the color scheme from the previous views into a given new one. 
		With such dynamic multi-scale color mapping we ensure that the viewer is able to distinguish structural detail that is shown on any given scale. 
		This technique has been tested by users with an expertise in structural biology and has been overall well received.
		
		\begin{classification} % according to http://www.acm.org/class/1998/
			\CCScat{Human-centered computing}{Visualization}{Visualization application domains}{Scientific visualization}
		\end{classification}
		
	\end{abstract}
	

	%% The ``\maketitle'' command must be the first command after the
	%% ``\begin{document}'' command. It prepares and prints the title block.
	
	%% the only exception to this rule is the \firstsection command
	\section{Introduction}
	\label{introduction}
	\maketitle
	%\keywords{Molecular Visualization, Bioinformatics Visualization}
	
	With improving technology, more and more data across all levels---from atomic to compartment---is being gathered on viruses and cells. 
	Today it is possible to display an ever increasing amount of this data at once, up to and beyond an entire human immunodeficiency virus (HIV)~\cite{muzic2015cellview}, with its complete macromolecular composition.
	All levels can be present; we can start at the compartment level and zoom in past the proteins, their domains and secondary structures, all the way to the amino acids and atoms (see Figure \ref{teaserImage}). Visualizations of HIV are not only used for research purposes, but also to communicate its basic properties to a broader audience, as in Figure~\ref{fig:motivation}, which is what we are interested in.

	
	%Colors are used to distinguish elements on each scale.
	Illustrators carefully select color assignments for each detail level of their illustrations. 
	In Figure~\ref{fig:motivation}, the illustrator depicts different protein types by color in the overview on the right. 
	In the close-up on the left, he uses different shades of blue to distinguish between the protein domains, which are not indicated in the overview. 
	In interactively zoomable visualizations, such a static single-scale color assignment will either lead to a loss or excess of information. 
	%Usually the color assignment is static.
	%At best, users can select their preferred color scheme. 
	%Unfortunately, single-scale color mapping will lead either to a loss or an excess of information.
	For example, if we apply categorical color coding to protein groups, then proteins can be easily discriminated, but secondary structures or atoms are not visually depicted (Figure~\ref{fig:NoiseDifference}, left).
	On the other hand, when color-coding individual atoms, the visualization is prone to salt-and-pepper noise in the overview levels (Figure~\ref{fig:NoiseDifference}, right).
	
	\begin{figure}
		\centering
		\includegraphics[width=1\linewidth]{Figures/motivation}
		\caption{Multi-scale illustration of HIV \cite{RCSBPDB2011}: overview of the virus on the right and close-up on the envelope protein on the left. In the close-up different shades of blue are used to discriminate between protein domains, and carbon atoms are slightly darker. }
		%		\caption{Motivation: Multi-scale illustration of HIV from David Goodsell. 
		%			The left part shows a close up on the protein which is indicated on the right part via the black line.
		%			In the close-up the illustrator used several shades of blue to distinguish between the different parts of the proteins which are not distinguishable in the wide view on the right side.
		%			Differentiation is also made between carbon atoms and the remaining ones by slightly shifting the luminance.}
		\label{fig:motivation}
	\end{figure}
	
	%In zoomable visualizations, this will either lead to information loss when zooming in, or salt and pepper noise when zooming out.
		
	%A naive visualization that defines color maps for each level and blends them may at first glance seem sufficient.
	A naive approach to multi-scale color mapping would be to independently define colors for each zoom level and then blend them while zooming. 
	However, several issues can occur:
	First, with independent color assignments for each zoom level, colors may change significantly when zooming.
	This may not only cause disorientation when zooming due to considerable color changes, but may also cause artificial hues or grayed out colors when blending between levels \cite{chuang2009hue}.  
	%This will not only affect understanding how two levels are connected, but also comprehension if the user is between levels.
	Second, there is a loss of hierarchy information when transitioning from one level to the next. 
	For example, when looking at two neighboring compartments and zooming in, it may be hard to maintain an overview which compartment certain proteins belong to. 
	%For example, if a user is looking at two neighboring compartments and zooms in where they meet, then he can not tell where one ends and the other begins, as the compartment level color coding is blended away. 
%	This may cause orientation problems due to the inherent hierarchy of the data.
	%An atom belongs to an amino acid, which in turn belongs to a domain of a protein, all the way to the top.
	To take the data hierarchy into account, Tennekes and de Jonge~\cite{tennekes2014tree} proposed a color space for hierarchical visualizations. 
	Their approach was targeted towards static visualizations and therefore assigns unique hues to each child node in a tree. 
	However, this leads to poor scalability with respect to color discriminability. 
	The HIV consists of 46 protein types, each divided further into multiple protein domains, secondary structures, amino acids, and atoms. 
	However, this scalability issue can be resolved by exploiting the interactive navigation capabilities -- and thereby caused dynamic visibility changes -- of our system. 
	
	
%	Therefore, a visualization of the data must fulfill the following requirements: 
%	One, structures should be distinguishable.
%	Two, the transition from one level to another must be smooth.
%	Three, the inherent hierarchy of the data must be preserved.
%	Finally, high visual appeal is also important for general-audience visualizations. 
	
	
%	There are several ways how to fulfill these requirements. 
%	Tenneken and de Jonge~\cite{tennekes2014tree} sub-divide the color space hierarchically so that each branch has its own hue.
%	As the tree is traversed towards the leaves through the structures of the cell, the hues become subdivided.
%	A compartment could be red, the proteins of that compartment different shades of red, and so forth.
%	However, this approach scales poorly with respect to color distinguishability. At smaller scales, colors can become indiscriminable.\\
%%	Inherent brightness variations due to shading can additionally influence color perception and limit the number of distinguishable colors.\\
%	%It might appear to be a good idea to branch out into luminance and saturation, in addition to hue.
%	%However, this means that the tree expands into three different dimensions.
%	%This can cause issues when understanding the data.
%	%Varying hue, saturation and luminance all at once can easily lead to cognitive overload, as it is difficult to operate in three dimensions at once. 
%	%Furthermore, in an illuminated or shaded scene, two objects with the same hue but different luminance that are next to each other might be %misconstrued as just one object, with the varying luminance userstood as changing structure. 
%	%As such, there are significant perceptual and cognitive restrictions placed on color coding. 
	
	We propose the semantic color zooming method Chameleon for multi-scale visualizations of cell or virus-like structures, based on a view-dependent, hierarchical color scheme.
	Starting from the highest hierarchy level, we progressively free up unused color space and redistribute it to visible elements defined by the current zoom level and item visibility.
	Our contributions are: 
	\begin{enumerate}
		\item A view-dependent, hierarchical hue palette for expressive color mapping of multi-scale structural biology models, 
		\item usage of chroma and luminance to minimize visual clutter and encode structural properties across multiple zoom levels, and 
		\item results from a small expert user study, showing that users can distinguish structures on multiple scales through dynamic color mapping, while rating the visualization as highly appealing. 
	\end{enumerate}
%	In the HIV as shown in Figure~\ref{teaserImage}, the user initially sees the different compartments. 
%	As the user zooms in, the proteins receive more distinct colors based on their compartment. 
%	As compartments and proteins disappear, the colors of the visible proteins are adjusted to enhance discernibility.  
%	As the viewer zooms further in, the domains of the proteins will become distinct, then the secondary structures, and eventually even the atoms.%, whose colors are predefined by convention.
%%	We will present the concept of our hierarchical color palette, implementation details for real-time rendering in a large scene, and results of a user study.
%%	In Section~\ref{Overview} we explain the basic structure and idea.
%%	Section~\ref{sec:hue} describes the implementation details of the coloring .
%%	In Sections~\ref{sec:chroma} and \ref{sec:luminance} we describe additions that support the visualization.
%%	In Section~\ref{sec:results} we describe the results.
%%	Section~\ref{sec:study} contains a user study.
	
	%\begin{figure*}
	%	\centering
	%	\includegraphics[width=1\linewidth]{Figures/Picture2_}
	%	\caption{Multi-scale visualization of HIV. (1) Cross-section of the virus, proteins are grouped based-on their compartments, and can be distinguished by their colors. (2) Zoom-in on the 1EX4 protein (3) The two domains of the protein are shown. (4) The secondary structures are show for first domain: yellow is for the helices, blue is for the sheets, and green is for the remaining atoms, (5) CPK color coding based on the atom type (blue is for Nitrogen, red is for Oxygen, grey is for Carbon)}
	%	\label{fig:Picture2}
	%\end{figure*}
	
	
	
	%One realm in which this system can be supported in is color. 
	%Color has been consistently and effectively used to seperate objects and sections from each other, and can also be used to display information about the object at the same time. 
	%Therefore, it would be advantageous to use these benefits in such a system. 
	%However, there are significant challenges in doing so. 
	%First, there are not that many easily distinguishable hues. 
	%For example, with constant luminance and chroma, the just noticeable distance - the distance between two colors where the a human can distinguish them - is equal to N degrees, based on a distance of 2.3~\cite{mahy1994evaluation}. 
	%However, this is of course not enough to be easily distinguishable. If 10 times the just noticeable distance were used, we would only have N colors. 
	%Furthermore, if we subdivde the colors when zooming in, similar to a tree, then the discriminability becomes worse with each leve. 
	%Certainly, it is possible to branch out into saturation and luminance as well. 
	%However, varying hue, saturation and luminance all at once can easily lead to cognitive overload, as it is difficult to operate in three dimensions at once. 
	%Lastly, in an illuminated or shaded scene, two objects with the same hue but different luminance that are next to each other might be misconstrued as just one object, with the luminance being used to indicate structure. 
	%As such, there are significant perceptual and cognitive restrictions placed on color coding. 
	
	
	\begin{figure}
		\centering
		\includegraphics[width=1\linewidth]{Figures/all3}
		\caption{Comparison image of HIV with coloring based on compartments (left), secondary structures (middle), and atoms (right). All different levels can be seen in Figure~\ref{fig:zoom_continuum}.}
		%		\caption{Motivation: Multi-scale illustration of HIV from David Goodsell. 
		%			The left part shows a close up on the protein which is indicated on the right part via the black line.
		%			In the close-up the illustrator used several shades of blue to distinguish between the different parts of the proteins which are not distinguishable in the wide view on the right side.
		%			Differentiation is also made between carbon atoms and the remaining ones by slightly shifting the luminance.}
		\label{fig:NoiseDifference}
	\end{figure} 
	
	
	
	%from here old \newline
	%Biological organisms can be viewed on different scales. 
	%For example, the human body consists of organs, cells, proteins and molecules. As more detailed data is becoming available across all levels, it is possible to combine visualizations of multiple scale levels into a single integrated visual environment. 
	%This poses new challenges for visualization experts, including seamlessly adapting the levels of detail of structural representations for real-time rendering, .... (experts, please address the challenges).
	%
	%A challenge which has not been addressed so far is color-coding. Consider, for instance, the human immunodeficiency virus (HIV).
	%To understand its viral lifecycle, researchers are investigating the shape of its compartments, the role of the individual proteins in viral replication, the secondary structures, as well as structural properties of binding sites on the atomic level. 
	%Traditionally, researchers use dedicated visual representations for each level of scale, and illustrators provide hand-crafted visualizations to communicate new findings to the general public. 
	%Each of these scale levels uses a distinct color coding so that observers are able to distinguish and identify the structures. Can we show existing examples here? 
	%When integrating multiple scales into a single zoomable visualization, it is therefore necessary to not only provide a seamless structural zooming, but also a color-coding mechanism that takes the current level of detail into account. 
	%While successively providing more levels of detail of the structures when zooming in, we are severely limited in the number of available colors due to perceptual constraints and limitations of the monitor hardware. 
	%
	%We propose a semantic zooming method for visualizing color-coded a virusmulti-scale visualization based on a view- dependent hierarchical color-scheme. 
	%Starting from the lowest zoom-level, we iteratively split up the available color space to the number of necessary colors defined by the current zoom level and item visibility.
	% Our method thereby trades discriminability of individual elements against temporal coherence. 
	%In the HIV example (refer to teaser image), the user initially sees the different compartments. 
	%As the user zooms in, the proteins receive more distinct colors based on which compartment they are in. As compartments and proteins disappear, the colors of the visible proteins are adjusted to enhance discernibility.  
	%As the viewer zooms further in, the domains of the proteins will become distinct, and eventually even the atoms, whose colors are predefined by convention. 
	
	\section{Related Work}

%	We divide the related work in two sections. In the first section we cover previous work about appropriate usage of colors in visualization, and their perceptual impact. 
%	In the second section we cover related work about large scale molecular rendering, to which we build our technique upon.
%		
%	\subsection{Colors in Visualization}
	The selection of a color map for data depends heavily on the visualization goal. 
	Not only clear visibility, but also harmonious and appealing colors can be important~\cite{ihaka2003colour}, as well as the assignment and mixing of colors~\cite{wang2008color}. 
	There are many points to consider, and as a result guidelines have been published on how to decide which color scheme is most appropriate~\cite{bergman1995rule}, \cite{healey1996choosing}. There have also been guides aimed at two dimensional color maps, such as by Bernard et al.~\cite{bernard2015survey} and the software ColorMap-Explorer by Steiger et al.~\cite{steiger2015explorative}.	
	Furthermore, several tools have been developed to assist users select appropriate colors for maps, such as Colorbrewer~\cite{harrower2003colorbrewer}, and color maps for clusters of data, such as ``i want hue''~\cite{iwanthue} and XCluSim~\cite{l2015xclusim}. 	
	Such clustering can, however, cause perceptual issues, either due to the large number of clusters or their layout.
	In cases such as colored maps, visually dominant structures may visually suppress small groups or areas~\cite{lee2013perceptually}.
	Visualization of information such as can be found on maps can lead to small areas being next to much larger ones. 
	In this case, it may be difficult to spot the small areas, and lowering the saturation of the larger areas allows the small ones to stand out more.
	Recognition may also be affected by contrast effects which may need to be dealt with~\cite{mittelstadt2014methods}. 
	Particular care needs to be taken when dealing with higher dimensional data~\cite{mittelstiidt2014revisiting}, so the distances between the clusters do not become distorted. 
	
	While there has been intense research on color mapping in visualization in the past, there have been only very few works related to multiscale visualization.
	Tree Colors use a tree-based method~\cite{tennekes2014tree} that attempts to overcome the above issues in the case of hierarchical structures. 
	The tree method uses HCL space (a cylindrical coordinate version of CIELab with Hue , Chroma (Saturation), and Luminance) and gives each cluster a different hue. 
	The root of the tree has no saturation, i.e. grey, and the hue is divided up into different wedges. A hue wedge is assigned to each branch, with some space cut out between branches, in order for there to be a jump in color from one wedge to another. 
	As the tree spreads out, the saturation of the nodes increases, and each level gets its own smaller wedge. 
	Essentially, each level has its own hue ring with a defined chroma. 
	However, the technique was designed for static visualizations, where all colors are visible at the same time. Therefore, the number of possible colors, for example in a close-up, is severely limited, leading to discriminability problems.
	In contrast, our method allows for dynamic shrinking and growing of wedges based on visibility. 
	In addition, we also allow for overlapping wedges if a clear structural separation is available. 
	This supports discriminability of items through color and shape. 
%	 and depth, allowing for overlap to occur at the lower levels. 
%	If some of our branches' nodes are not visible, then the wedge will shrink, allowing neighbouring branches to expand. 
%	This assists color discernment by the user when looking at the objects of a subset of the branches.
	
	
	%Color maps are used often in visualization. Their structure depends heavily on the application, as has been shown in [Colour for Presentation Graphics], [Color Design for Illustrative Visualization]. Several tools have been developed 
	%
	%Color maps are used often in visualization. 
	%Their structure depends heavily on the application, as has been shown in [Colour for Presentation Graphics], [Color Design for Illustrative Visualization], 
	%
	%A Rule-based Tool for Assisting Colormap Selection, http://ultra.sdk.free.fr/docs/Image/Colors/ARule-basedToolfo0AssistingColormapSelection.htm], [Choosing Effective Colours for Data Visualization], 
	%[a survey and task-based quality assessment of static 2d colormaps], [explorative analysis of 2d color maps]. 
	%Several tools have been developed to assist users select appropriate color maps, such as colorbrewer, or iwanthue, [http://tools.medialab.sciences-po.fr/iwanthue/] and XCluSim, which are aimed at generating colors for clusters of data. 
	%However, when dealing with numerous clusters, special attention must be paid to the perceptual qualities of the color map
	
	
	%\subsection{multiscale view}
	%Sometimes hierarchical data can also be viewed on multiple levels at once, for example a protein can be viewed on the overall structure as well as on the atomic structure~\cite{kauker2013rendering}. 
	%Alternatively, distortions of the object or different rendering levels in different areas of the camera may be used. 
	%For example, in~\cite{hsu2011rendering} the area in the center of the camera is rendered as closer in. 
	%This is achieved through using non-linearly bent camera rays and multiple cameras. 
	%Parts of the object can also be distorted, for example by widgets such as in~\cite{sudarsanam2008non}, where local areas are distorted using non-linear perspectives. 
	%Alternatively, the user might want to zoom into a structure. An example of this is~\cite{artignan2009multiscale} in which a large hierarchical graph is visualized.
	%The graph has a large depth, and to investigate certain nodes the user must zoom in. During this, the node expands and changes color while its children become exposed. 
	%This is recursively applied down the branch, allowing for an arbitrarily deep descent.
		
%	\subsection{Multi-Scale Molecular Visualization}
	
	The development of new modeling techniques for three dimensional molecular structures led to a rapid increase in size of the studied datasets.
	To keep up with the progress, new visualization methods were specifically developed to address this challenge, such as by Lampe et al.~\cite{lampe2007two} or Falk et al. \cite{falk2013atomistic}. 
	An overview of the state-of-the-art in visualization of biomolecular structures is given by Kozlikova et al.~\cite{kozlikova2015visualization}. 
	
	To support seamless zooming in molecular visualizations, Parulek et al.~\cite{parulek2014continuous} introduced seamless transitions between different levels of coarseness for the representation of the molecular surface based on the distance from the camera.
	Their goal was not only to reduce the computation cost, but also to utilize the shape as a means to reduce high-level details and noise when observing the structure in its entirety.
	Le Muzic et al.~\cite{le2014illustrative} extended this approach to allow for real-time rendering of structures with up to tens of billion atoms. %, using tessellation shaders to switch between different degrees of coarseness for the molecular structures, on-the-fly. 
	cellVIEW \cite{muzic2015cellview} renders such large-scale molecular scenes using Unity3D, a popular 3D engine. 
	It showcases large molecular structures generated with cellPACK \cite{johnson2015cellpack}, a tool developed to procedurally generate accurate and multi-scale models of entire viruses and cells.
	While these tools provide the foundation to interactively navigate massively packed molecular landscapes, they currently do not have sufficient visual expressiveness to effectively reveal structural information beyond the protein level. 
%	Lampe et al.~\cite{lampe2007two} pioneered real-time rendering of large-scale atomic data on consumer level hardware. 
%	They extended the fast billboard-based approach introduced by QuteMol \cite{tarini2006ambient}, by rendering the structures per residues rather than per atom, thus reducing the memory bandwidth usage and the GPU driver overhead. 
%	Lindow et al. \cite{lindow2012interactive} followed-up by using  instanced rendering to draw entire structures instead.
%	For each molecule type, they generate a 3D grid of the atoms which is stored on the GPU, and then ray-casted upon rendering.
%	Falk et al. \cite{falk2013atomistic} further refined the method with improved depth culling and hierarchical ray casting to achieve faster rendering performance for even larger scenes.\\
%	Parulek et al.~\cite{parulek2014continuous} introduced seamless transitions between different levels of coarseness for the representation of the molecular surface based on the distance from the camera.
%	The goal was not only to reduce the computation cost, but also to utilize the shape as a means to reduce high-level details and noise when observing the structure in its entirety.
%	Their technique uses real-time ray-tracing and offers high quality surface details, but it does not scale well in terms of performance when compared to atom-based rendering methods.
%	A novel approach, for real-time rendering of structures with up to tens of billion atoms, was later on introduced by Le Muzic et al.~\cite{le2014illustrative}. 
%	Their approach, also based on level-of-detail, uses tessellation shaders to switch between different degrees of coarseness for the molecular structures, on-the-fly and upon the rendering operation.
%	The entire scene is thus rendered efficiently in a single draw call, approaching zero GPU-driver overhead. 
%	As a follow up, they developed and released cellVIEW \cite{muzic2015cellview}, a tool designed for rendering large-scale molecular scenes, which was implemented with Unity3D, a popular 3D engine.
%	cellVIEW was primarily developed to showcase large molecular structures generated with cellPACK \cite{johnson2015cellpack}, a tool developed to procedurally generate accurate and multi-scale models of entire viruses and cells.\\
	Chameleon is built upon cellVIEW, and is an attempt to improve understanding during exploration of multi-scale molecular scenes generated with cellPACK.
	%cellVIEW leverages GPU computing and parallel programming to provide a fluid user experience, Chameleon was developed with the same programming paradigm.
	
%	\begin{figure}[t]
%		\centering
%		\includegraphics[width=1\linewidth]{Figures/Picture2_.jpg}
%		\caption{Multi-scale visualization of HIV. (1) Cross-section of the virus, proteins are grouped based-on their compartments, and can be distinguished by their colors. (2) Zoom-in on the 1EX4 protein (3) The two domains of the protein are shown. (4) The secondary structures are show for first domain: yellow is for the helices, blue is for the sheets, and green is for the remaining atoms, (5) CPK color coding based on the atom type (blue is for Nitrogen, red is for Oxygen, grey is for Carbon)}
%		\label{fig:Picture2}
%	\end{figure}
%	


	

		
	\section{Chameleon Overview}
	\label{Overview}
	
	Mesoscale datasets feature many relevant properties which are present at different scale levels.
	The molecular properties that we provide are, from the largest to the smallest scale level: compartment (or protein group), protein type, protein domain, secondary structure, and atom type.
	According to domain experts, these are the most relevant properties. % in visual analysis of three dimensional molecular structures.
	%This information is internally declared and accessible for each single rendered atom, which allows us to perform dynamic coloring.
	Scientific illustrators are using these properties to modulate the color palette when generating static visualizations of proteins at different levels, as shown in Figure~\ref{fig:motivation}.
	However, this requires manually setting up the color palette for each level, which can be extremely tedious for an interactively zoomable visualization of an entire virus. 
	%which can be cumbersome when dealing with a multitude of large datasets.
	Our goal is to provide a dynamic coloring mechanism that automatically visualizes the most relevant information for any given zoom level, thereby fulfilling the following requirements: 
		
	\begin{enumerate}
		\item On each zoom level, associated main structures (i.e., those structures that result in the best visibility in terms of screen size) should be clearly discriminable from each other. 
		\item When navigating, the transitions between the zoom levels should be smooth to avoid abrupt appearance changes of the visualization or orientation loss. 
		\item The inherent hierarchy of the structures should be reflected in the color coding. 
		\item The visualization should be aesthetically pleasing to engage a broad audience. 
	\end{enumerate}
	
	We manipulate all three color components of the HCL color space to fulfill these requirements: 
	We use the \textbf{hue} to distinguish between structures at the respective zoom levels, as described in Section \ref{sec:hue}. 
	The \textbf{chroma} is used to increase color discriminability for elements in the focus against the context (Section \ref{sec:chroma}). 
	Finally, we indicate structures from lower hierarchies in the \textbf{luminance} channel to mimic illustrator techniques (see Figure \ref{fig:motivation}) and to smoothen color transitions (Section \ref{sec:luminance}).
	All objects in the scene must be fully opaque, as transparency for densely packed molecular data can lead to unpredictable and confusing color mixtures. 
	We use CIELab and HCL color palettes, which are perceptually linear. 
	This means we can quantify the dissimilarity between colors by their Euclidean distance.
	We describe how we dynamically adapt the hues as the user is panning the scene to ensure color discriminability even in a scene with dozens of different entities (Section \ref{sec:dynamic}), and how hues are sub-divided hierarchically as the user zooms further into the scene (Section \ref{sec:hierarchy}). 
	Finally, we demonstrate the effectiveness of our technique in a user study with professionals and students from the field of molecular biology (Section \ref{sec:study}). 
	
	
	
	%This information should also be coherent between levels.
	%To provide smooth and logical transitions across levels, we use a hierarchical color coding approach inspired by a tree-based coloring method~\cite{tennekes2014tree}.
	%Based on perceptual reasoning, clarified in the introduction, we use isoluminant colors, and we choose to only vary the hue channel to generate the color palette. 
	%
	%On the first level of the hierarchy, we first assign portions of the hue circle to each group of protein types.
	%Protein types of a given group are then given a unique hue value on the corresponding arc, as shown in Figure \ref{fig:coloroverview}.
	%In the initial state, the size of the hue arcs is set according to the number of protein types contained in each group. 
	%Spacing between hue values of neighbour protein types of the same group is proportional to the number of type per group and the size of the arc. 
	%
	%Due to the large difference in terms of size between groups and proteins, it is very likely that several compartments will be less or no longer visible as we zooming-in on a single protein. 
	%Based on this principle we update the color palette on-the-fly using the visibility information which we extract from the previously rendered frame.
	%For each protein type, we compute the percentage of visible elements, as well as the screen coverage in pixels for displayed proteins.
	%We sum up those properties for all the protein types of a group to deduce a weighting coefficient which is then used to scale the size of the hue arcs of the groups as shown in Figure~\ref{fig:coloroverview}.
	%
	%When zooming further in, we progressively start to reveal colors of the underlying protein properties, such as the chains, or secondary structures.
	%For coloring the subsequent levels, we sample hue values around the hue of their parent as shown in Figure~\ref{fig:coloroverview}.
	%We use pre-defined camera distance thresholds to determine when to transit to the next level.
	%To ensure a smooth transition, the hue distance between the parent and the children is progressively scaled until reaching a pre-determined offset value.
	%%In the case of protein types, the coloring mechanism allows to enlarge the size of the hue arcs while ensuring no overlap between neighbooring groups. 
	%%However, when displaying other properties it would be more challenging to reuse the same principle, because of ** TODO REASONS **.
	%To ensure a minimum degree of overlapping hue ranges between two neighbours, we use a focus + context to reduce occurence of recurrent colors in the background.
	%
	%Atoms constitute the final level of our hierarchy.
	%In molecular visualization this information is commonly associated with predefined colors also called CPK coloring.
	%To transit to this final level we perform linear color interpolation in RGB space, between the color from the previous level (secondary structures) and final atom color.
	%The coefficient of interpolation is defined according to the camera distance and pre-defined distance values *** MANU'S MAGIC COLOR INTERPOLATION HERE ? ***.
	%
	%\textbf{. With a static hierarchical color coding approach, the hue arcs are predefined on the highest level, and multiple colors are then generated for the lower levels by manipulating channels like chroma luminance} \\
	%
	%\textbf{. The strictly static approach has two limitations:}
	%
	%\textbf{. It uses luminance variation to generate distinct colors, which is not preferable to use with a lit 3D environment} \\
	%
	%\textbf{. Hue arcs are statically defined, therefore, in case the entire wheel is occupied, colors generated inside the wedge do not have an optimum degree of discriminability.  } \\
	%
	%\textbf{. Indeed, HUE is such a stronger cue to differentiate between types** add better justification **}
	%
	%\textbf{. Therefore we suggest a method to define color coding hierarchically, where the initial hue value would no longer be statically defined }. \\
	
	%\textbf{. The principle is to use the view information to enlarge to interact with the size of the hue arcs on the highest zoom level.} \\
	%
	%\textbf{. A naive approach would be to simply increase the hue arcs as the camera gets closer to an element and to interpolate between levels based on the distance. }
	%
	%\textbf{. However, by increasing the arc lengths arbitrarily we will inevitably run into a case where two consequent segments would overlap } \\
	%
	%\textbf{. This shall be avoided when possible in order to ensure a maximum level of clarity } \\
	%
	%
	%\textbf{. We address this problem differently based on the zooming level, via two different approaches} \\
	%
	%\textbf{. Indeed, in mesoscale datasets, the multiple semantic levels from entire viruses or cells, down to single atoms, are not evenly spaced.} \\
	%
	%\textbf{ . **TODO** ruler figure with all the scales}
	%
	%
	%\textbf{By observing the scale we realize that the size difference between levels beneath the protein levels is much lower than the levels above.} \\
	
	
	%\section{Details Info Dump}
	%
	%full sentences are commented in the tex
	%\textbf{. Molecules have multi-scale properties which can all be characterized by color } \\
	%
	%%.The scenes that we are displaying represent meso-scale biological structures and comprise a large number of molecules (proteins or lipids).
	%%.Each protein carry essential properties that is used to convey a different information for each single scale (TODO: Do a figure to explain).
	%%.Each of these properties can be visualized and highlighted using a specific color coding.
	%
	%\textbf{. Molecules have Bottom-Up properties, type and group} \\
	%
	%%. Molecules can be of different species or type, which characterize their structure.
	%%. A group of molecules with similar structures is referred as instances of type X.
	%%. Types are also categorized in groups, based on their location or function. 
	%
	%\textbf{. Molecules have Top-Down properties, domain, secondary structures, and atom type} \\
	%
	%%. Each molecule comprise a set of atomic particles.
	%%. Atoms have different types, C, H, O, N,...
	%%. Atoms are assembled in groups to form the amino-acids.
	%%. Amino-acids are chained and form segments of amino-acids that are characterized by their shape such helices and sheets, this is called the secondary structure.
	%%. The secondary structures are grouped together and divide the proteins in different domains.
	%
	%\textbf{. BOTTOM-UP PROPERTIES} \\
	%
	%\textbf{. We use hierarchical color assignments for Bottom-Up properties (we defined wedges in the color wheel for the groups and types inside a group are assigned a color in the corresponding wedge )} \\
	%
	%%. We decide to chose iso-luminant colors (for aesthetic reasons).
	%%. We first assign a wedge of the color-wheel for each group.
	%%. In the initial state, the size of the wedge is proportional to the size of the group in terms of protein types.
	%%. The colors of the protein are defined accordingly to the color of their group (hierarchical).
	%%. Only the hue differs between different types of molecules
	%%. Inside a wedge each protein type of a group is assigned to a portion of the wedge with equal spacing between two protein types.
	%%. Should a wedge be enlarged or shrunken, the color assignment is set relatively to the size of wedge.
	%
	%\textbf{. Static tree color maps offers limited discrimination for a large number of colors because it uses other properties to vary colors inside a wedge, HUE IS A MUCH STRONGER CUE} \\
	%
	%%.The hue circle is limited (360), therefore with several groups comprising tens of individual types we will quickly run out of colors.
	%%.In the tree-color paper they solve this problem by generating more colors for each wedge using the additional channels (chroma \& luminance).
	%%. This approach has a poor potential for discrimination between different properties since inside a predefined inside a wege colors will still remain rather similar. 
	%
	%\textbf{. NAIVE APPROACH: Grow the size of color wedges dynamically when zooming in to vary the hue of the colors inside a wedge} \\
	%
	%%. Rather than using different channels like luminance and chroma we want to keep discriminating colors with HUE because it is such a strong cue.
	%%. In order to keep using the hue to discriminate between colors the size of the wedges must be scale according to the zooming distance.
	%%. However as the wedges grow their is no mechanism that would prevent two neighbour wedges to overlap which could results in misleading coloring choice.
	%
	%\textbf{. Wedges may overlap, solution is to use visibility information to control the scaling of the wedges} \\
	%
	%%. Rather than scaling the wedges according to the zooming distance we suggest to grow or shrink the wedges according to what is currently visible in the current viewport.
	%%. For example, if all molecule groups are equally visible, the size of their wedges will be proportional to the size of the groups in terms of protein species.
	%%. If a protein group is partially visible or not-visible at all, the corresponding wedge will be scaled accordingly, thus freeing space in the color wheel for other wedges to grown
	%%. [Make figure to show example]
	%
	%\textbf{. Read Visibility Information must be read form the current viewport} \\
	%
	%%.We analyse visibility information from the rendered frame to check which molecules types are actually currently visible.
	%%.The visibility information we use is screen coverage and number of visible instances.
	%%.The number of visible protein can be low, while few molecule can have a large screen pixels coverage if located close to the camera.
	%%.Similarly the screen coverage can be low while a large number of molecules may still be visible, if camera is looking a the scene from far away.
	%
	%\textbf{. Use Visibility Information to control the sizes and the layout of wedges, via force fields} \\
	%
	%%. Once we have the visibility information for each species we evaluate the weight of the species group for scaling the wedge.
	%%. We use a force based layout to arrange the wedges along the color wheel.
	%%. Each wedge comprise a centroid that can move either left of right, in one dimension.
	%%%. The position is then mapped from 1D to a 2D circle for debugging.
	%%. Each wedge acts as a circular force field centred around the centroid and which pushed the other wedges away.
	%%. The radius to force field is proportional to the size of the group, the number of visible instances, and the percentage of pixels that are occupied by instances of the group.
	%%. The radius of the force field is computed as follows: write formula here.
	%%. The integration of the forces is computed as follows: write integration formula here.
	%%. To make sure that wedge centroids are not pushed away too much from their original location and are shifting in color too much we also apply attraction forces from the centroids to their original location
	%
	%
	%\textbf{. TOP-DOWN PROPERTIES} \\
	%
	%\textbf{. To transition between two down properties we rely mostly on the camera distance rather than the visibility information} \\
	%
	%\textbf{. We use HUE again as a cue to discriminate between sub-domains of a protein} \\
	%
	%\textbf{. We chose HUE values for the chains that are located in the vicinity of the Protein HUE value} \\
	%
	%\textbf{. We perform smooth transition between protein HUE and terminal HUE chain as the viewer zoom-in} \\
	%
	%\textbf{. When focusing on proteins to observe the chains, the chain HUE values of neighbouring or likely to cross/overlap those of the focus} \\
	%
	%\textbf{. We came up with the idea to prioritize the display of chain properties to proteins with a high screen coverage} \\
	%
	%\textbf{. Additionally when zooming closely to a protein to observe bottom-up properties, we desaturate proteins with low screen coverage to reduce clutter cause by the display of too many top-down property colors for context molecules } \\ 
	%
	%
	%\textbf{At the finest zoom-level we show the atom colours, these colors follow bio-chemical standard and are therefore predifined. } \\
	%
	%\textbf{We perform color smooth color interpolation between the current color of the atoms and their terminal colors. } \\
	%	
	%\textbf{To improve the bla-bla, we use the interpolation technique by Manu which constists of bla-bla-bla} \\
	\begin{figure}[t]
		\centering
		\includegraphics[width=0.3\linewidth]{Figures/hueWheel.png}
		\caption{Iso-luminant hue ring with 21 distinct colors, with luminance 75 and chroma 40 in HCL color space.}
		\label{fig:hueWheel}
	\end{figure}
		
	
	
	
	
		
		
		
		
	
	
	\section{Dynamic Hue Palette}
	\label{sec:hue}
	
	At the highest hierarchy level (compartment, as illustrated in Figure \ref{teaserImage}a), our task is to find colors for each individual protein type that allow users to discriminate the proteins, but also understand their hierarchical grouping into the compartments. 
	%Also, aesthetics are important, as we target our work at interested users from a broader audience. 
	%Since chroma and luminance as used for focus+context visualization and smoothing transitions, 
	To visually categorize the protein types, we initially assign each protein type within each compartment a unique hue value. 
	Hues are selected from an iso-luminant hue ring, centered in the gray spot, such as shown in Figure \ref{fig:hueWheel}. 
	To maintain good contrast for encoding shape properties through shading, we fixed the luminance value to 75. 
	With this luminance value, we also can use a wide radius to fit the hue ring within the sRGB gamut, leading to a maximum chroma of 40. 
	Figure \ref{fig:hslvshcl} shows a comparison between a hue palette picked from an HSL ring (left) and an iso-luminant HCL ring (right). 
%	\textbf{tbd: remove this comment. Removed better visibile for iso-luminant}
	Mind how the structural properties are better visible in the iso-luminant pastel color palette on the right. 
	
	

			
%	Due to aesthetic reasons, as well as the use of luminance and chroma as described in Section~\ref{Overview}, we opted to choose only saturated and iso-luminant colors, resulting in a pastel color palette. 
%	Figure \ref{fig:hslvshcl} shows a comparison between an iso-luminant and non-iso-luminant color palette.
%	We therefore keep the chroma and luminance constant and distinguish proteins by hue only, which means hues are selected from an iso-luminant hue ring.
%	To have better control over color discriminability, we use CIELab and HCL color palettes  which are perceptually linear. 
%	This means we can quantify the dissimilarity between colors by their Euclidean distance.\\
%	To select suitable chroma and luminance values, we investigated which luminance values result in the largest possible hue ring when converting colors from CIELab space back to sRGB. 
%	In an offline procedure, we picked eight extreme a and b values with equal distance from the non-chromatic center with a given L value and iteratively moved them towards the center until the resulting CIELab color was lying within the sRGB gamut. 
%	The smallest vector magnitude of $\vec{ab}$ thereby defined the radius and chroma for the given luminance, respectively. 
%	We found that a luminance of 75 represents a good value, leading to a maximum chroma of 40 (see Figure \ref{fig:hslvshcl}). \\	

	For the initial color assignment of protein types associated with individual compartments, we allocate hues from the hue ring to protein types with respect to four parameters: 
%	In order to calculate the color of the compartments and their proteins, we can distribute the hues of the hue ring to the different proteins.
%	The color of the compartment will then simply be at the center of the proteins that belong to it.
%	To distribute hues from the hue ring to the proteins, we sample the hues with respect to four parameters: 
	1) the number of compartments $n$, 2) the number of protein types $m_i$ within each compartment $1 \leq i \leq n$, 3) the optimal color distance $d$ between structures, which will be elaborated below, and 4) the minimum color spacing $s$ between compartments. 
	%This corresponds to the top row of (b), (c) and (d) in Figure~\ref{fig:coloroverview}.
	The first parameter defines the number of ``wedges'' that are overlaid on the hue ring, where each wedge represents the color range of a compartment, as illustrated in Figure \ref{fig:coloroverview}, top row. 
	The second parameter controls the relative angular width of the wedges. 
	The third and fourth parameter control the actual angular width of the wedges: 
	Given the chroma $C^*$ (i.e., radius) of the hue ring and the optimal Euclidean color distance $d$, the optimal angular distance between neighboring proteins within the same compartment is defined as: 
	\begin{equation}%
	\alpha_{opt} = arcsin\frac{d}{C^*}. %
	\end{equation}%
	%
	In CIELab color space the ''just noticeable difference'' (jnd) is assumed to be 2.3\cite{lee2013perceptually}.
	Using the jnd would of course lead to poor discernibility. 
	We discovered that roughly 5 jnd steps were needed to allow for easy discernibility. 
	\begin{figure}[t]
		\centering
		\includegraphics[width=0.75\linewidth]{Figures/hslvshcl}
		\caption{Comparison between two color palettes with varying hues and constant saturation/lightness using HSL (left), and constant chroma/luminance using HCL (right). 
			Unlike HSL, the HCL color space provides true isoluminant colors when varying the hue with constant chroma/luminance values.
			%Mind how the dark blue colors, inside the virus and next to the membrane, make it hard to distinguish individual proteins in a lit environment.
		}
		\label{fig:hslvshcl}
	\end{figure}
	%In the hue ring in Figure \ref{fig:hueWheel}, we chose a distance $d$ between neighboring colors of 11.5, which corresponds to five \textit{``just noticeably different''} steps of 2.3 in CIELab color space \cite{lee2013perceptually}. 
	With this setting and a chroma radius of $C^*=40$, $\alpha_{opt}$ is 16.7$^{\circ}$, which allows for a maximum of 21 distinct hues. 
	%With a lower $d$, we found that individual color dots could not be properly distinguished any more. 
%	The hue ring in Figure \ref{fig:hueWheel} shows 21 distinct colors, where the distance $d$ between neighboring colors is around 12, which corresponds to approximately five \textit{``just noticeably different''} steps of 2.3 in CIELab color space \cite{lee2013perceptually}, and the spacing $s$ is set to zero.  
%	We choose this $d$ of 12 as our optimal color distance. 
	However, in the HIV, we have 46 distinct protein types $\sum_{i} m_i$ distributed to five compartments $n = 5$. 
%	\textbf{to manu: this has been added below. see next todo (added comment there) TODO: check which spacing between wedges we used for our example figures / video!} 
%	Empirically, we found that $d$ around 11 delivers results which correspond to around 5 \textit{``just noticeably different''} steps of 2.3 in CIELab color space \cite{lee2013perceptually}, allowing for easy discrimination. 
%	Assuming no spacing between compartments (i.e.\, $s=0$), this would result in only 32 distinct colors, which is far below the number of proteins in the HIV model. 
	We use a minimum spacing $s=5^{\circ}$, so that our angular distance  $\alpha$ between protein type colors is therefore below the minimum $\alpha_{opt}$: 
	\begin{equation}%
	\alpha= \frac{360  - n \cdot s}{\sum_{i} m_i}. %
	\label{eq:wedge}%
	\end{equation}%
	%
	This means that in the initial overview zoom-level protein colors can be very similar and hard to distinguish. 
	In the overview zoom level, this effect is actually desirable to avoid salt and pepper noise. 
	However, as we zoom in, we want increasing discriminability. 
	We therefore introduce a view-dependent color adaptation approach to increase $\alpha$ dynamically, based on the current visibility.  %over which the user can manually set some parameters if he so desires. (???)
	
	
	\begin{figure*}[t]
		\centering
		\includegraphics[width=0.95\linewidth]{Figures/coloroverview}
		\caption{Overview of Chameleon's dynamic and hierarchical hue selection scheme for (a) an exemplary two-level hierarchy of four protein groups (A,B,C,D) and a total number of 20 different protein types: For the current viewport (b), visibility information is extracted (c) and the color palette is updated. Zooming further towards protein type 10 splits up the protein type hue to three different domain colors (x,y,z).}
		%			\caption{Overview of our dynamic and hierarchical hue selection scheme. (a) Shows the first two levels of the hierarchy, in this demonstration case there are four groups of protein types (A,B,C,D) with an overall number of 20 different protein types, (b) Shows the current viewport, wide view on the top and close-up on the bottom, where the red square represents the actually viewport, (c) The visibility information is extracted from the current viewport and analysed, (d) The color palette is updated to include visible elements only, (e) The following levels of the hierarchy (domains only in this case) are revealed as we zoom in on a protein of type 10, which features 3 different domains (x,y,z).}
		\label{fig:coloroverview}
	\end{figure*}
	%\textbf{MWA END: my suggestion is to remove the next paragraph}
	\subsection{View-Dependent Color Adjustment}
	\label{sec:dynamic}
	
	%In the initial state, we first generate a color palette assuming that all the compartments are visible.
	As the user zooms in and explores the scene, large parts of the scene may not actually be visible in the current viewport, as is illustrated in the lower row of Figure~\ref{fig:coloroverview}(a-c).
	In this configuration the color palette becomes underexploited. %, and can be improved to increase discriminability. 
	We therefore re-compute and optimize the color palette on-the-fly as proteins appear and disappear.
	An overview of the mechanism is illustrated in Figure~\ref{fig:coloroverview}.
	
	
	To determine which protein groups occupy unnecessary space in the color palette, we extract visibility information by analyzing the previously rendered frame.
	For each protein group, we determine the number of visible protein types $m_i$. 
	A protein type is visible, if at least one screen pixel is occupied by a protein of type $i$. 
	According to Equation \ref{eq:wedge}, the angular distance $\alpha$ between the hues increases as the number of visible protein types across all protein groups $\sum_{i} m_i$ decreases. 
	
%	For each protein group, we derive a group visibility coefficient to scale their corresponding wedge on the hue ring. 
%	This coefficient is calculated based on the number of visible protein types within the group. 
%%	This coefficient is calculated based on the visibility of each protein type contained in a given group.
%%	The visibility of a given protein type is defined as a boolean value: visible or not visible.
%%	A protein type is not visible if none are displayed on the screen.
%%	A protein type will also be set as visible if some elements are located close to the camera and occupy a significant number of pixels in the viewport, even when the overall percentage of visible elements is low.
%%	Therefore we also take the pixel occupancy of the proteins into account.
%	The visibility value of a given protein type is computed as follows:
%	%
%	\begin{align}
%	c_{i}&=\begin{cases}%
%	1, & \text{if $p_{i}>t_{p}$ or $v_{i}>t_{v}$}.\\
%	0, & \text{otherwise}.%
%	\end{cases}\\
%	C &= \left\lbrace c_{1}, ... , c_{n} \right\rbrace,  %
%	\end{align}
%	%
%	where $c_i$ corresponds to the visibility factor of a given protein type $i$, $p_i$ corresponds to the ratio of pixels occupied by proteins of type $i$, and $v_i$ is the ratio of proteins of type $i$ that are visible.
%	The parameters $t_{p}$ and $t_{v}$ correspond to predefined thresholds for the screen coverage and visibility, respectively. 
%	\textbf{In this paper they are equal to 0, i.e. they are visible if they are on the screen.}
%	$C$ is a set of $n$ protein types that constitute a group.
%	\textbf{TODO: are we sure this is correct? Could it be as simple as just counting all protein types that have at least one visible pixel per compartment? Otherwise: what happens if a protein type has visible pixels below the threshold? Which colors are they assigned?}
%	
%	The group visibility coefficient $w$ is computed as follows:
%	
%	\begin{equation}
%	w = q\sum_{i=1}^{n} c_{i}, c_{i} \in C, 
%	\end{equation}
%	
%	where $q$ is a scaling factor which is proportional to \textbf{the total number of proteins.}%the number of protein types in that group. 
%	\textbf{TODO: again, is this correct? a scaling factor proportional to the total number of protein types in a group multiplied by the visible protein types -- could this be just the ratio visible by total? But this would not fit to Figure 4. My guess would be that simply $m_i$ of the previous section is set, and the smaller $m_i$, the bigger the possible angular distance between the hues. Please clarify!}

	As visualized in Figure \ref{fig:coloroverview}d, the hue ring is divided proportionally to the protein groups' numbers of visible proteins. 
	As the number of visible protein types can be potentially small, we allow the user to determine a maximum angular distance of a protein group to avoid excessive color changes while panning. 
	%In our HIV showcase, we use 110$^{\circ}$. 
	%, which in our case is can be reached if the user is looking at the secondary structure level of only one compartment. 
	%The miminum angle between groups is 5 degrees. 
	
%	\textbf{Once we compute the group visibility coefficient of each protein group, we divide the hue circle proportionally to the group visibility coefficient to determine the size of individual hue sections. 
%	The coefficient corresponds to the angle on the hue circle. 
%	We give control over the maximum angle to the user. 
%	This allows the user to take control if necessary.
%	For example, if there are 2 groups with 2 proteins each, they would all be equi-distant from each other.
%	By specifying a maximum angle, the user can force the proteins to group.
%	If the user specifies a maximum angle of 0, then each protein group only has one color.
%	We also allow the user to control the angle between 2 groups.
%	This means the user can control how distinct groups are from each other, if he so desires.}
	
	\subsubsection{Extracting Visibility Information}
	\label{sssec:extracting}
	We leverage GPU computing in a post-processing operation, in order to compute the visibility of each protein type efficiently.
	Upon rendering, we generate an additional offline texture which contains, for each pixel, the unique identifier of the rendered protein.
	We priorly declare two GPU buffers which will, for each protein type, store the occupied pixel count and the total number of visible proteins, respectively.
	Subsequently, in a dedicated compute shader, we iterate through all the pixels, and we increment the pixel counter corresponding to the protein type stored in the video memory.
	At the same time, we also flag in a dedicated GPU buffer the proteins whose unique IDs are present in the generated texture.
	This information will allow us to determine the number of visible instances for each protein type.
	In a second pass and in a dedicated compute shader we then iterate through all the protein instances.
	For each protein which was flagged as visible in the previous pass, we increase the number of visible instances corresponding to the protein type.
	Since the computation is done in parallel it is important to use atomic intrinsic functions to increment the counters, in order to avoid concurrent access to the same value from two different threads.
	
	\begin{figure}
		\centering
		\includegraphics[width=0.85\linewidth]{"Figures/force-based layout"}
		\caption{Force-based hue assignment: Initial wedge placement (a) and resulting force-based placement (b). Red arrows indicate the default hues for the wedge centroids, and black arrows represent the forces. }
		\label{fig:force-basedlayout}
	\end{figure}
	
	\subsubsection{Force-Based Hue Assignment}
	
	
%	\textbf{We use a force based method in order to determine the positions of the groups on the hue circle [manu: what we define as the wedges]}
% Wedges are defined in the second paragraph of Section 4 (each wedge represents the color range of a compartment)
	%By default, each group is assigned a centroid hue value, which we refer to as default centroid hue.
	As we move the camera and affect the visibility of the proteins, the angles of the protein-group wedges on the hue ring are dynamically growing and shrinking. 
	To determine the optimal location of the protein-group wedges on the hue ring, we use a force-based method to reposition the wedge centroids on the ring. 
	%we modulate the size of the groups on the hue ring.
	%Upon modulation of the group sizes, we must also reposition the group centroids on the ring.
	%A naive and non-iterative approach would be to 
	We start by positioning a first wedge on the circle, and then place the remaining wedges subsequently on the circle, as illustrated in Figure \ref{fig:force-basedlayout}a.
	While the position of the first wedge on the hue ring can be arbitrarily defined with this approach, the other wedges are not guaranteed to be located as near as possible to their default centroid (i.e., the initially assigned wedge centroid with all visible protein types).
	This could lead to unnecessarily large hue shifts for some protein groups while navigating, as shown in Figure~\ref{fig:force-basedlayout}a.
	
	To avoid this issue, we use a force-based layout for the positioning of the group centroids on the hue ring.
	The forces are applied in a single dimension, i.e, along the hue ring, and include distance constraints between the groups as well as attraction forces between groups and their default positions.
	We then integrate the forces, using Euler Integration to compute the new positions of the groups until reaching a state of equilibrium.
	For a given group $i$, the distance-constraint response-force with another group $j$ is computed as follows:
	%
	\begin{equation}%
	y(i, j) = l(g_{i},g_{j})max((r_{i}+r_{j}) - |g_{i} - g_{j}|, 0), 
	\end{equation}%
	%
	where $l$ corresponds to the direction of the response, i.e., whether the hue angle should increase or decrease, $g$ is the position of the group centroid, and $r$ is the radius of the distance constraint and corresponds to the protein group's wedge radius plus the spacing between group wedges. 
	%corresponds to half of the protein group's wedge angle and the user-defined spacing between the wedges:  
%	\begin{equation}
%	r_i = \frac{m_i \cdot \alpha + s}{2}. 
%	\end{equation}
%	\textbf{Done, but left to reminder me to check again TODO: I tried to simplify here, but I am not sure whether this is correct. Please check!} 
	%and which corresponds to the weight computed from the visibility information and described in Section~\ref{sec:dynamic}.
	In other words, the force-based hue assignments aims to keep the resized wedges close to their default centroids, while avoiding overlaps between neighboring wedges.  
%	\textbf{Essentially, all it does is determine if two groups overlap or not and to what degree. If they do no overlap, the force is equal to 0. The w takes the user specified minimum distance between wedges into account.}
    % Not true, it also tries to keep the wedges close to their original position
	For a single group, the overall forces -- comprising of attraction and repulsion forces -- are computed as follows:
	%
	\begin{equation}
	f_{i} = (g_{i} - I_{i}) + \sum_{j=1}^{n, i \neq j} y(i,j)
	\end{equation}
	%
	The first part of the right side of this equation corresponds to the attraction forces, where $I$ corresponds to the initial group position.
	The second part is the sum of repulsion forces between the given group and the other ones.
    Additionally we also include a damping value of 0.2 (reduce velocity by 20\% per time step) in the integration calculus to smooth-out the motion of the group centroids when the viewport and visibility configuration abruptly change. This does not affect the final color assignment for a view, merely the transition.
	
	\subsection{Hierarchical Colors}
	\label{sec:hierarchy}
	
	%\subsection{Principle}
	
	%\textbf{MWa rewrite BEGIN}
	
	As we zoom further into the details of the proteins, we begin to reveal the colors corresponding to the following levels (domains, secondary structures, atoms). 
	To ensure logical transitions between levels and to maintain hierarchical information, we introduce a hierarchical hue picking method. 
	For each protein type, the hue ring is further sub-divided into wedges to color-code protein domains, and individual protein-domain hues can further be sub-divided to secondary-structure wedges. 
	
	To select hues for $m$ protein domains, the angular distances $\gamma$ between the domain hues are calculated as follows: 
	%
	\[
	\gamma = min(\alpha_{opt}, \beta / m)
	\]
	%
	where $\beta$ is the maximum size of the domain wedge and $\alpha_{opt}$ is the optimal angular distance, as defined in Section \ref{sec:hue}.
	This means that the wedge will grow linearly with the number of domains until it reaches the angle $\beta$, at which point the angle between domains will start to shrink. 
	We set $\beta$ to 180 so that a single protein would not cover more than half of the hues. 
	A larger $\beta$ could lead to a loss of hierarchical information. 
	Choosing a lower $\beta$ may cause domains within a single protein to be hardly distinguishable.  
	The domain hue wedge is centered around the protein hue value, as illustrated in Figure \ref{fig:overlap}.
	Mind that domain hue wedges can overlap across proteins. 
	%Figure \ref{fig:overlap} illustrates the construction of the coloring of the protein domains, as well as the overlap that can occur.
	This is another major difference to the hierarchical coloring technique introduced by Tennekes and de Jonge \cite{tennekes2014tree}, who assigned unique, yet hardly distinguishable colors on all zoom levels for static tree visualizations. 
	In our case, being able to clearly distinguish domains is an important task in structural biology, which is difficult without clearly distinguishable colors. 
	To overcome misinterpretation caused by overlapping hue wedges between proteins, we added context-de-saturation on demand. 
	%facilitated by structural properties as well. 
	
	
	\begin{figure}
		\centering
		\includegraphics[width=0.4\linewidth]{Figures/overlap}
		\caption{Hierarchical color assignment for the protein chains. 
			The spacing between the protein domains (x,y,z) and (x',y',z',w') is predetermined based on the number of domains, and domain-hue wedges can also overlap. 
			%Unlike the tree-based coloring approach~\cite{tennekes2014tree} we allow colors to be reused across domains of different protein types (see 10 and 12) to offer more discriminability.
		}
		\label{fig:overlap}
	\end{figure}
	
	

	
	\subsubsection{Interpolating Between Levels}
	
	The individual zoom levels (compartment, proteins, domains, etc.) are associated with specific distances of the camera to the scene. 
	In our HIV example, distance values were chosen so that the structures associated with the zoom levels were optimally visible. 
	Assigning zoom levels to camera distances is task-dependent. 
	Some items, like atoms and amino acids, have very similar sizes (see Figure \ref{fig:hivScale}) and would therefore occupy similar zoom ranges, i.e. it is not possible to uniquely determine what information a user would be interested in for some camera distances.
	Thus, it depends on the users' priorities to select or omit certain levels for color coding. 
	
	\begin{figure}
		\centering
		\includegraphics[width=0.7\linewidth]{Figures/hivscale}
		\caption{Illustration of the scales of HIV. Note that some items have very similar sizes, like atoms and amino acids. }
		\label{fig:hivScale}
	\end{figure}
	
	
	%We switch between the levels, such as protein and domain levels, based on the distance from the rendered atoms to the camera and arbitrarily defined values which delimit where each level begin and ends.
	To smoothen the transition between zoom levels, we interpolate the hue values in between the levels.	
	This transition is performed in post-processing on the GPU, in a dedicated shader program.
	In addition to the unique protein identifier texture mentioned in Section~\ref{sssec:extracting}, we also generate an additional offline texture upon rendering, which contains the unique identifier of each rendered atom.
	While iterating through all the pixels, we fetch their unique atom identifiers from the offline texture.
	The identifiers allow us to collect, directly from the shader program, all the needed information concerning the rendered atoms, and the identifiers were priorly uploaded to the video memory (group, protein type, domain, secondary structure, and atom type).	
	We also use the previously rendered depth texture to retrieve the world-space position of a pixel in the shader.
	Then, from the world position of each pixel, we compute the world space distance to the camera.
	From the camera distance we are able to compute the current degree of transition between the closest levels, as well as the hue values associated with the two closest zoom levels.	
	Finally, the hue of a fragment is computed by performing a linear interpolation of the hue value of the two levels, as illustrated in Figure \ref{fig:zoom_continuum}.
	
	In our current implementation, users have to define the camera distances for the zoom levels manually. 
	In the future, we plan to investigate automatic camera-distance settings, based on the screen size of the structures associated with the zoom levels.
	
	
		\begin{figure}
			\centering
			\includegraphics[width=1\linewidth]{Figures/zoomfigure}
			\caption{Interpolation of hue and luminance values for a fragment: based on the world space distance to the camera, the interpolation factor between the two closest levels (protein and domain) is computed and used as blending factor between protein and domain hue, as well as domain and secondary structure luminance offset. 
				%If the distance is too large, only the proteins are shown.  
				}
%			\caption{Interpolation of hue and luminance depends on the position of the view. The black camera in the top line shows the position of the viewer with respect to the different levels. The grey crosses show the corresponding positions for interpolating hue and luminance.
%				The hue is equal to a linear interpolation of the two neighbouring levels shown in the middle line, here compartment and protein. Luminance is equal to a linear interpoation of the next two levels, here protein and domain, visible on the bottom line. The interpolation is based on the ratio of the distance to the neighbouring levels, here 0.3 and 0.7. }
			\label{fig:zoom_continuum}
		\end{figure}
	
	
	\subsubsection{Pre-Defined Color Palettes}
	
	In some cases, it can be desirable to use pre-defined color palettes instead of automatically calculated categorical colors. 
	In our HIV showcase, we use pre-defined atom color codes for the highest zoom level (see Figure \ref{teaserImage}e), to support domain knowledge, such as CPK coloring for atoms. 
	In this case, Chameleon simply blends to those pre-defined colors when zooming to the atomic level. 
	
	%\textbf{MWa rewrite END -- remove next paragraph in case of acceptance}
	%
	%Once the protein colors are defined, the colours of the following zoom-levels (chains, secondary structures) are chosen hierarchically, based on the color of their parent in the previous level.
	%For example, the hue value of a chain is sampled around the hue of its protein, with an arbitrarily defined offset, see Figure~\ref{fig:coloroverview}.
	%These colors are then progressively reveal as we zoom into the proteins.
	%We switch between the colors of the different levels based on the distance of the proteins to the camera and user defined distance values which delimit where a levels being and ends.
	%In between levels we perform linear color interpolation for smooth and logical transitions between the levels.
	%This operation is performed in a post-processing operation, for each pixel we have access internally to all the necessary  information concerning an atom, (group, protein type, domain, secondary structure and atom type).
	%By retrieving the world-space position of a pixel in the shader, we are able to compute the world space distance to the camera, and determine the the degree of transition between two levels.
	%The color of a fragment is them computed by performing a linear interpolation of the hue value of the previous level and the next one. 
	%The hue offset between two level are priorly determined based on the number of domains, or secondary structures.
	%We set the minimum hue offset to be superior or equal to 20, because of ***MANU EXPLAIN REASONS HERE***.
	%The maximum size in hue angle for all elements of a level, chains or secondary structures, is set to 180 to reduce the use of too many colors of a single level.
	%The main different between this approach is that we do not prevent overlaps, because of limitations of orginal tree color approach ** Manu or Nik explain reasons here **.
	
	
	
	
		
		
		\begin{figure}[t]
			\centering	
			\includegraphics[width=0.9\linewidth]{Figures/desaturated}
			\caption{Without (a) and with (b) desaturated peripheral colors.}
			\label{fig:results_3}
		\end{figure}
	
	

	
	
	\section{Context Desaturation}
	\label{sec:chroma}
	
	%	\textbf{MWa rewrite BEGIN}
	
	Due to our hierarchical color assignment, domain colors of neighboring proteins or secondary structures of neighboring domains may be assigned identical colors (Figure~\ref{fig:overlap}).
	To increase color discriminability, and reduce occurrence of similar colors, we modulate the chroma to generate a focus+context effect. 
	By clicking on a protein of interest, we define a spherical 3D region around the protein, which constitutes the focus region. 
%	We select the protein with the highest screen coverage in the central region \textbf{TODO: DEFINE!} of the screen as focus element.
%	Based on the size of the protein and its location, we define a spherical region in 3D which constitute the focus region.
	Outside this region, we progressively decrease the chroma value down to 0 as we zoom towards the focused protein, to ensure optimal color discriminability of the focus protein's colors with respect to all other colors in the scene, as can be seen in Figure~\ref{fig:results_3}. 
%	The zoom levels distances between which the desaturation effect begins and ends are arbitrarily defined.

	%	Figure \ref{fig:focusContext} shows a single focus protein with XX domains. 

	
	%	\textbf{Just to be sure: this does not solve the problem of similar colors of secondary structures of different domains on the same protein?}
	
	%	\textbf{MWa rewrite END -- remove next 2 paragraphs in case of acceptance}
	
	%	The colors of the lower hierarchy-levels (chains, secondary structures) are chosen hierarchically, based on the color of their parent in the previous level.
	%	For example, the hue value of a chain is sampled around the hue of its protein, with an arbitrarily defined offset, see Figure~\ref{fig:coloroverview}.
	%	Our system provide optimal hue distribution of protein colors for proteins based on the visibility information, which guarantees that protein will always be assigned unique and distinct colors.
	%	However, this is not the case for following levels of the hierarchy, where chains colors are likely to overlap with those of neighbouring proteins.  
	%	This limitation is principally caused by the significant discrepancies between the different levels.
	%	Indeed between single proteins and protein domains the difference in term of size is much smaller than between compartments and proteins, see Figure~\ref{fig:Picture2}.
	%	Given such constraint, we must rapidly ensure that the color information for the next level will be available, which cannot easily be achieved based-on visibility and without dramatically reshuffling the colors.
	%	
	%	Therefore we rely on a focus+context approach instead, to optimize the view and guaranty a minimum degree or repeated colors.
	%	Indeed, when closely observing protein properties, it is very unlikely that the viewer will also observe properties of all the surrounding proteins, as commodity hardware does not offer enough pixels to render all the context proteins with enough details to be relevant to the viewer.
	%	Therefore we define a focus region outside which the colors of the proteins will be desaturated to reduce occurrence of colors used in focus region.
	
%	\begin{figure}		
%		\centering
%		\includegraphics[width=0.5\linewidth]{Figures/goodsell_protein}
%		\caption{An illustration of a protein using a popular color scheme from David Goodsell. The hue is used to discriminate between the protein domains, while the luminance is used to differentiate carbon atoms from the rest.}
%		\label{fig:goodsell_protein}
%	\end{figure}
	
	
	
		
	
	
	\section{Luminance Modulation}
	\label{sec:luminance}
	
	So far, we used the hue channel to discriminate structures on different zoom levels and the chroma to distinguish focus proteins from the context. 
	The final color channel we manipulate is luminance. 
	Molecular illustrators sometimes use the luminance channel to indicate structural properties in lower hierarchy levels, as shown in the close up in Figure \ref{fig:motivation} or in the "Molecule of the Month"~\cite{goodsell2016}. 
	This is a reasonable choice, given that hue is known to be an effective channel to encode low-frequency information, while luminance is more effective to encode high-frequency information~\cite{bergman1995rule}. 
	In addition, encoding information from an additional zoom level can support orientation when blending between zoom levels. 
	
	%	\textbf{Figure goodsell layer by goodsell himself}
	
	For each hierarchy level, we therefore not only assign unique hues, but also unique luminance values. 
	We modulate our base luminance value of 75 by up to a value of 15, as illustrated in Figure~\ref{fig:results_2}.  
	%10 for secondary structures and 15 for atoms, to avoid extensive visual clutter and not to interfere with shading cues. 
	%As the user zooms closer to the respective level the luminance modulation is reduced.
	%\textbf{manu, I don't know which figure, and I don't think this is necessary to illustrate that detailed. TODO: illustrate by figure for protein 10 and 12 from wedge figure. } 
%	In the example of Figure \ref{fig:zoomLevels}, we use a luminance range of 20 to distinguish the sub-elements. 
	With this small modulation, the luminance channel serves only as a subtle indication of lower-level structural properties, to avoid extensive visual clutter and not to interfere with shading cues.  
	
	Like the hue, the luminance value is defined by the distance of the camera to the respective structures. 
	Given an interpolation factor derived from the zooming distance to the pre-defined zoom levels (see Figure \ref{fig:zoom_continuum}), luminance values are interpolated between the next two hierarchy levels with the current interpolation factor, as illustrated in Figure \ref{fig:zoom_continuum}, bottom line. 
	This way, the hue and the luminance encode different hierarchy levels and thereby generate an effect similar as shown in the close up in Figure \ref{fig:motivation}. 
	%Yet, both color channels are seamlessly interpolated for smooth transitions. 
				
	\begin{figure}[t]
		\centering
		\includegraphics[width=0.9\linewidth]{Figures/huemodulation2x2}
		\caption{Comparison of domain level (top) and secondary structures level (bottom) without (left column) and with (right column) luminance modulation.}
		\label{fig:results_2}
	\end{figure}
	
	\begin{figure*}[t]
		\centering
		\includegraphics[width=1\linewidth]{Figures/results_4}
		\caption{Various snapshots from the Chameleon system.
			As the camera position changes, the discriminability between protein types is optimized.
			The color palette widget at the bottom left allows us to visualize the distribution of the groups along the hue ring. The hue ring is not intended to be directly interpreted. It is a technical complement to support intuitive understanding.}
		\label{fig:results_1}
	\end{figure*}
	
		
	\section{Results}
	\label{sec:results}
	
	To showcase the capabilities of the Chameleon, we applied it to a mesoscale molecular scene. 
	The dataset was provided by domain experts and modeled with cellPACK \cite{johnson2015cellpack}, a tool for the procedural generation of large biomolecular structures, incorporating the most recent knowledge from structural and systems biology. 
%	cellPACK summarizes and incorporates the most recent knowledge obtained from structural biology and system biology to generate comprehensive mesoscale models. 
%	Based on experimentally obtained data (e.g. data such as protein structure, concentration and spatial distribution), the tool is able to generate entire models of viruses and cells via a packing method based on collisions constraints.
	We use cellVIEW \cite{muzic2015cellview} for the rendering part, which is a tool designed to efficiently render large molecular scenes on the GPU and is implemented in Unity3D. 
	
	The dataset which we showcase is a model of an HIV particle in the blood serum which contains 20502 instances of 46 different protein types including two lipid membrane layers.
	The protein types are grouped together based on their location.
	There are 6 different protein groups in the dataset; the blood plasma proteins (18 types), the lipids (2 types), the envelope surface (5 types) and interior proteins (15 types), the capsid surface (1 type) and proteins inside the capsid (5 types).
	Figure \ref{teaserImage} shows progressive zooming from the entire virus to single atoms.	
	Initially, the blood plasma proteins in green, and the matrix protein in purple, dominate the color palette because they have more protein types than other compartments, like the orange capsid proteins.	
	As we get closer to the capsid proteins, we observe that the colors become more distinguishable.	
	To visualize the results of the view-dependent color-palette optimization more precisely, we also developed a palette widget, shown in Figure~\ref{fig:results_1}, bottom left.
%	Figure~\ref{fig:results_2} shows all the sequential steps we take to progressively reveal the protein properties as we zoom in.
	
	%The second dataset, shown in Figure \ref{fig:nofig} is a model of an immature HIV which contains 1081 instances of 13 different protein types, and one bi-lipid membrane. \\	
	Chameleon relies on GPU computing to provide a smooth and responsive user experience.
	Since we perform all the coloring operations in post-processing, the size of the dataset has only little impact on the performance. 
	We benchmarked the computation speed at HD resolution (1920$\times$1080) on a machine equipped with an Intel Core i7-3930 CPU 3.20 GHz machine coupled with a GeForce GTX Titan X graphics card with 12 GB of video RAM.
	We measured \textbf{0.5 ms} on average to count the visible instances when zooming out on the entire dataset, which is the most extreme case since a very large number of proteins are visible.	
	It took \textbf{1.2 ms} to compute the screen pixel coverage of the protein types with the same configuration.
	The last stage of the pipeline, in which we assign the final hue, chroma, and saturation values to each pixel, took \textbf{1.3 ms} on average. This also includes the cost of reading back the visibility information to the CPU for the force-based hue assignment.
		
	%\section{Technique (section written by Nicholas)}
	%
	%When applying a coloring scheme to data of this type, several things need to be taken into account. 
	%First, the representation should support the level the user is looking at, e.g. not show the protein domains when the user is looking at the compartment level. 
	%Second, switching from one level to another should not be confusing.
	%Third, the user should be able to easily identify useful information at the level he is looking at. 
	%Because predetermining all the colors for each item in the scene and not allowing for view dependency will, with enough data, guarantee that data points will become indistinguishable. 
	%Fourth, the coloring must allow the user remain orientated and determine what belongs to the stuff he is interested in. 
	%For example, he needs to know where a compartment ends and the next one begins.
	%Stress the fact that temporal coherence and discriminability by color are contradicting each other if we need a lot of colors (give numbers for HIV!). 
	%Ware (?) points out that luminance is more useful for encoding high-frequency information, while hue is easier to interpret for encoding low-frequency information. 
	%
	%This is also reflected in the well-known ColorBrewer color schemes, where colors of categorical palettes differ primarily by hue, while quantitative color schemes operate mostly on luminance level.  
	%We therefore use utilize the HCL color space that separates these two properties into different dimensions (luminance is the vertical axis, while hue and chroma are represented on the perpendicular planes as polar coordinates). 
	%Another useful aspect of the HCL color space is that it is simply an alternative representation of the CIEL*a*b* color space and therefore perceptually linear. 
	%This means that we can linearly link changes in the color space to perceptual responses. 
	%We start by assigning each item on the lowest LOD a distinct hue. 
	%Since the lowest hierarchy level comprises the entire model, this assignment is static and does not change with the viewing angle. 
	%Given the number of elements $n$ on the lowest LOD, the desired luminance and chroma, the hue of the ith element is simply defined by $h_i=i*360/n$. 
	%This results in $n$ isoluminant colors with equidistant hues. 
	%(Chroma is luminance-depending if we consider the sRGB boundaries, but we dont do this now!)
	%We use a hue circle here, but any parametric curve within the HCL space could be used. 
	%In this case, the colors would not be isoluminant, but still equidistant in the perceptually linear color space. 
	%Each section applies force on its neighbouring section, proportional to the number of different kinds of proteins that are visible. 
	%This means that the section can grow and shrink, depending on visibility. If a compartment is not visible, then the section shrinks to a size zero. 
	%
	%However, a degree of consistency is still desired. It would be unwanted for a compartment to switch over to the opposite color, such as blue to yellow.  
	%As such something needs to be in place to keep compartments from moving too far.
	%The switch to the proteins color occurs when the distance is greater than 5*2.3 =5*jnd in cielab space [Mahy 94 evaluation after adoption]. 
	%This is equal to an angle of X on the hue circle.
	%
	%Another problem is how do we choose the colors for the domains? Their color needs to be view dependent as well as near to the color of the protein they belong to. 
	%The color of the chains does not Interact with the color of the other proteins, but does if they are showing their chains. 
	%Whether or not the chains are shown depends on the how close the camera is to the protein, unless the color distance would be below a certain amount (5*2.3) (8.8 degrees). 
	%The hue circle is reused to show the colors of the chains. See fig[]. 
	%The chains dont cause any force on the proteins, and the proteins cause no force on the chains. 
	%The chains of two different proteins can cause force on one another if they are being shown. 
	%Because the chains would normally surround the entire circle, they only push each other away to a maximum distance of X. 
	%This allows for the chains to have similar colors to the proteins.
	
	\section{User Study}
	\label{sec:study}
	Since interactively explorable multi-scale visualizations of biology models have only become available very recently, there is no comparable approach how to represent biological structures across multiple scales. 
	Dynamic visual discrimination, apart from geometric levels of detail \cite{parulek2014continuous}, have not been studied so far in the biological field. We therefore decided for a qualitative evaluation since there is no clear baseline for a comparative lab experiment, in order to answer two research questions: 
	\begin{enumerate}
		\item Does Chameleon color mapping support discrimination of structures on multiple scales? 
		\item Are the dynamic color changes by Chameleon distracting / unpleasant in the exploration process? 
	\end{enumerate}
	
	To answer these two research questions, we asked five students and professionals in the field of biology to perform two tasks. 
	In the first task (\emph{structure identification task}), users were asked to identify structures on multiple levels of detail.
	We based our task description on the a previous publicly available description of the HIV capsid at PDB-101~\cite{goodsell2016}
	Based on this description of the HIV capsid, users were asked to identify the following structures: 
	\begin{enumerate}
		\itemsep0em 
		\item one of the 12 pentamer capsid proteins, 
		\item the N-terminal and C-terminal domain of the capsid protein, 
		\item the alpha helix in the N-terminal domain stabilizing the hexamers / pentamers, 
		\item the binding site of Cyclophilin A, which is a loop on the surface of the capsid protein with several proline amino acids, and
		\item one methionine amino acid within the alpha helix.
	\end{enumerate}
	The last item was not included in the expert's task description, but was added as a representative task on the amino acid and atom level, respectively. 
	Since we did not color-code the amino acid level explicitly, users were given the hint to identify methionine based on the coloring of its sulfur atom. 
	To assess the performance in the structure identification task, we recorded whether users were able to correctly identify the above listed structures. 
	In the subsequent \emph{free exploration task}, users could freely navigate through the visualization, while thinking aloud. 
	All reported insights were noted. 
	Both tasks were video-taped and followed by a questionnaire and a semi-structured interview. 
	Before the study, users could play around with the tool to get familiar with the navigation, and were also instructed how to toggle the visibility of the protein groups. 
	
	With the structure identification task, we could assess whether experts with sufficient knowledge to understand molecular structures without additional text labels are able to identify the above structures using our system. 
	While our color mapping provided the necessary discrimination of individual structures in the respective zoom levels, the identification of the structures was only possible through their structural properties.
	Through the free exploration task, our goal was to assess whether users would notice and be distracted by our dynamic color mapping. 
	%Although our system is targeted towards a broader audience, the knowledge of our users allowed us to assess whether the structural information is sufficiently distinct without adding textual information. 
	
	Mind that structural information alone is not sufficient to identify structures below the protein level, as shown in Figure \ref{fig:comparison}. 
	In addition, performance measures of such complex tasks are rather hard to compare with only a small number of expert users performing the study. 
	
	
	%After a pilot study with two researchers (28 and 25, one female) in the field of biochemistry and proteomics, respectively, we improved the navigation controls of our system (\textbf{HOW??}), since we observed a strong negative impact on the ability to explore the scene. 
	We  report observations, questionnaire results, and feedback from five experts or students in the field of molecular biology (2 PhD students, one Post-Doc, one pharmacist, and one master student; one female, aged 24 to 31, all with normal or corrected-to-normal vision). 
	While the method is also aimed at the general audience, no such users were involved in the study. 
	The task description for such users would have to be rather long and detailed, leading likely to issues with text comprehension or revealing too much information. 
	
	\subsection{Results}
	
	Table \ref{table:identification} summarizes the performance of users in the structure identification task. 
	Except for user 3 (the pharmacist), all users were able to correctly identify all structures down to the secondary structure level. 
	User 3 mixed up the N and C terminals of the capsid protein, and the rest of the tasks are to some degree based on finding them.
	With regards to the amino acid, there was more than one kind of amino acid with a sulfur atom, and two users mistook it for the correct one.
	
	\definecolor{cc}{rgb}{0,0.5,0}
	\definecolor{cp}{rgb}{0.7,0.5,0}
	\definecolor{ci}{rgb}{1.0,0.0,0}
	\definecolor{cn}{rgb}{0.5,0.5,0.5}
	
	
	\begin{figure}
		\centering
		\includegraphics[width=1\linewidth]{Figures/comparison}
		\caption{Comparison between static protein coloring (left) and hierarchical color coding using Chameleon (right) for viewing a capsid protein hexamer on the protein domain level. }
		\label{fig:comparison}
	\end{figure}
	
	
	
		% 	{\scriptsize \begin{tabular}{ l l l l l l }
		% 			\toprule
		% 			Task \textbackslash User & 1 & 2 & 3 & 4 & 5 \\
		% 			\midrule
		% 			Pentamer       & \textbf{\color{cc}c} (100\%) 	& \textbf{\color{cc}c} (90\%) 	& \textbf{\color{ci}i} (70\%) 	%& \textbf{\color{cc}c} (very sure) 		& \textbf{\color{cc}c} (high)\\
		% 			C-terminal     & \textbf{\color{cc}c} (100\%) 	& \textbf{\color{cc}c} (70\%) 	& \textbf{\color{ci}i} %(10\%) 		& \textbf{\color{cc}c} (pretty) 	& \textbf{\color{cc}c} (quite) \\
		% 			N-terminal     & \textbf{\color{cc}c} (100\%) 	& \textbf{\color{cc}c} (70\%) 	& \textbf{\color{ci}i} %(10\%) 		& \textbf{\color{cc}c} (not very) 	& \textbf{\color{cc}c} (quite)\\
		% 			$\alpha$-helix & \textbf{\color{cc}c} (guess) 	& \textbf{\color{cc}c} (50\%) 	& \textbf{\color{cn}n} 		& %\textbf{\color{cc}c} (pretty) 	& \textbf{\color{cc}c} (not sure) \\
		% 			Binding site   & \textbf{\color{cc}c} (1\%) 	& \textbf{\color{cc}c} (85\%) 	& \textbf{\color{cc}c} (90\%) 	%& \textbf{\color{cc}c} (very) 		& \textbf{\color{cc}c} (pretty) \\
		% 			Methionine      & \textbf{\color{cc}c} (1\%) 	& \textbf{\color{cp}p} (90\%) 	& \textbf{\color{cn}n} 		& %\textbf{\color{cp}p (low)} 			& \textbf{\color{cn}n}  \\
		% 			\bottomrule
		% 		\end{tabular}}
	
\begin{table}
	 	
	 	\centering
	 	\caption{Structure identification task: \textbf{\color{cc}c} identified correct item, \textbf{\color{cp}p} partially correctly identified item, \textbf{\color{ci}i} identified incorrect item, \textbf{\color{cn}n} nothing found. User-reported certainty of correctness in brackets. First three were asked in percentage, the second two responded from high to low, which is shown in the table as 5 (highest) to 1 (lowest).}
	 	{\scriptsize \begin{tabular}{ l l l l l l }
	 		\toprule
	 		Task \textbackslash User & 1 & 2 & 3 & 4 & 5 \\
	 		\midrule
	 		Pentamer       & \textbf{\color{cc}c} (5) 	& \textbf{\color{cc}c} (5) 	& \textbf{\color{ci}i} (4) 	& \textbf{\color{cc}c} (5) 		& \textbf{\color{cc}c} (5)\\
	 		C-terminal     & \textbf{\color{cc}c} (5) 	& \textbf{\color{cc}c} (4) 	& \textbf{\color{ci}i} (1) 		& \textbf{\color{cc}c} (4) 	& \textbf{\color{cc}c} (4) \\
	 		N-terminal     & \textbf{\color{cc}c} (5) 	& \textbf{\color{cc}c} (4) 	& \textbf{\color{ci}i} (1) 		& \textbf{\color{cc}c} (2) 	& \textbf{\color{cc}c} (4)\\
	 		$\alpha$-helix & \textbf{\color{cc}c} (1) 	& \textbf{\color{cc}c} (3) 	& \textbf{\color{cn}n} 		& \textbf{\color{cc}c} (4) 	& \textbf{\color{cc}c} (2) \\
	 		Binding site   & \textbf{\color{cc}c} (1) 	& \textbf{\color{cc}c} (5) 	& \textbf{\color{cc}c} (5) 	& \textbf{\color{cc}c} (5) 		& \textbf{\color{cc}c} (4) \\
	 		Methionine      & \textbf{\color{cc}c} (1) 	& \textbf{\color{cp}p} (5) 	& \textbf{\color{cn}n} 		& \textbf{\color{cp}p (1)} 			& \textbf{\color{cn}n}  \\
	 		\bottomrule
	 	\end{tabular}}
	 	
	 	\label{table:identification}
	 \end{table}
	 
	 In the questionnaire, users assessed the identification of compartments, but also the proteins, as very easy  (see Figure \ref{fig:questionnaire}). 
	 However, the domain and secondary structure identification was rated as much more difficult. 
	 This is also reflected in the users' self-reported certainty of the identified structures (Table \ref{table:identification}). 
	 While the users were quite certain about the identity of a pentamer capsid, once they spotted it, they were least certain about the alpha helices stabilizing the hexamers and pentamers. 
	 All users, except for user~3, were able to identify the C- and N-terminal domains of the capsid proteins. 
	 All those users verbally referred to the domains by color. 
	 Two users also referred to the alpha helices by color. 
	 
	

In the free exploration task, all except for user 3 explored the virus. 
On average, they spent 10 minutes for exploration. 
Some users reported that they learned something new when exploring the visualization, such as that \textit{``HIV uses [the] host membrane''} and \textit{``how crowded everything is''}. 
The four users focused on different parts of the virus during their free exploration, such as the membrane (user 1 and 5), the proteins in the matrix (user 1 and 4), and the amino acids of the Cyclophilin A binding site (user 2). 

In the questionnaire, most users indicated that they the color change (see Figure \ref{fig:questionnaire}), but the confusion caused by these color changes were rated fairly low. 
When asked about the changing colors in the post-experiment interview, all users reported that they noticed changing colors when zooming to the atomic level. 
However, only one user noticed it on all levels, while a second one thought \textit{``something odd''} was occurring on the secondary structure level. 

In general, our users all issued the highest possible grade for visual appeal in our questionnaire. 
In the post-experiment interview, they explained that they considered the tool useful for presenting their research and educating students -- which is in line with our research goals. 
However, they also had suggestions for improvement, such as adding text labels, visually marking the termini of the protein domains, and providing a cartoon representation for secondary structures. 

\subsection{Summary and Discussion of Results}
 \begin{figure}
 	\centering
 	\includegraphics[width=1.0\linewidth]{Figures/questionnaires.pdf}
 	\caption{Average and standard error of responses on five-point Likert scale for questions concerning the ease of identification of structures (blue), as well as color changes and visual appeal (orange).}
 	\label{fig:questionnaire}
 \end{figure}
The performance and feedback of the molecular biologists in our study indicate that Chameleon supports users in identifying molecular structures on multiple scales. 
Users were equally successful identifying one of the capsid proteins forming a pentamer, and identifying the two domains of the capsid protein. 
The pentamer capsid protein differed only in shape from the more frequent hexamer capsid proteins, while the two different domains of the capsid proteins were encoded by color. 
However, the users reported lower certainty and higher task difficulty for the identification of the domains.
This is an indication that identification by structure is easier than identification by color alone -- yet, color can be used if no strong structural cues are available, as in our protein domain example.

On the secondary structures level, the identification rate was similarly high, but users were quite uncertain about their findings and reported a high task difficulty. 
On this level, alpha helices and beta sheets were discriminated by color, similar to Figure \ref{fig:results_2}. 
However, the particular alpha helix mentioned in the task description could only be identified as a helix by shape.
The request for an alternative cartoon representation for identifying structures on this level shows the limits of multi-scale color mapping without adapting the structural representation. 
In the future, it will be important to explore combinations of semantic zooming comprising both, structural and color information. 

User feedback shows that our system's dynamic color changes do not interfere with the users' workflow. 
While protein domains and secondary structures were mainly referred to by their color, only few users noticed the color changes (except at the atomic level) and none found them confusing. 
All users found the visualization highly appealing and useful for presentation and education purposes. 
We therefore conclude that Chameleon is a valuable extension to multi-scale molecular visualization and does not cause any notable distraction, but allows for efficient and pleasing visual encoding of protein sub-structures. 

	
%	We conducted a user study with domain experts in biology in order to evaluate our visualization and to improve it based on the feedback.
%	We wanted to know whether the colors helped to solve the tasks.
%	Furthermore, we wanted to know how disruptive the changing colors are, so we did not inform the users about their dynamic behaviour. 
%	Instead, we tested whether they would notice the change.
%	The user study was conducted in two study runs. 
%	In the first run, two domain experts (PhD students) tested the software. 
%	Their feedback was used to adapt the software, which was then tested by four domain experts (PhD and post-doc) and a master student. 
%	All users worked in the field of molecular biology. 
%	To conduct their research, the participants use visualizations on the protein or molecular level.
%	
%	%In the first iteration the secondary structures were identifiable through luminance, not color. They had the same hue as the domain they belonged to, simply lighter ($\beta$-sheets) or darker ($\alpha$-helices);
%	
%%	\subsection{Users}
%%	We gathered 7 domain experts. 6 were PhDs. and PostDocs, and one was a master student. All users were experts in the field of molecular biology. 
%%	To conduct their research, the participants use visualizations on the protein or molecular level.
%	
%	
%	\subsection{Study Design}
%	We performed a qualitative study instead of a quantitative lab experiment.
%	In a qualitative study, the user is given a visualization and is tasked with solving some questions. 
%	In contrast to a quantitative user study, where task completion times and errors across multiple conditions are compared, the goal is to measure what the user can discover about the dataset.
%	There are two reasons for this choice.
%	First, the task is too complex to be captured well by these simple measurements. 
%	Second, there is no established baseline condition.
%	Without means to distinguish structures on different search levels, the task would not be solvable and therefore either create a bias towards our technique or not fully demonstrate its potential.\\
%	The study consisted of two parts. In the first part the user was asked to identify structures on different levels. 
%	It also allows us to measure what information can be found.  
%	In the second part the users explored the HIV freely, and we observed what they discovered.
%	
%	\subsection{Structure Identification Task}
%%	\begin{figure}
%%		\centering
%%		\includegraphics[width=1\linewidth]{Figures/pentamerStudy}
%%		\caption{Rendering of Capsid during the second user study. In the center there is a pentamer, and to the left of it a hexamer.}
%%		\label{fig:pentamerStudy}
%%	\end{figure}
%	Based on a description designed by a molecular bioligist and an illustrator, the first task was to investigate the capsid of the HIV. 
%	The following is a shortened version of the description: \\
%	
%	\textit{
%		The capsid encloses the genome (2 strands of RNA) along with different viral proteins. 
%		The capsid protein is able to form hexamers and pentamers by shifting slightly in structure, and folds to form two domains connected by a flexible linker: the N-terminal domain and C-terminal domain. 
%		The N-terminal domain is involved in forming the hexamers or pentamers, and the C-terminal domain is involved in dimer contacts between hexamers / pentamers. 
%		There are two $\alpha$-helices in the N-terminal that stabilize the hexamers and pentamers. 
%		As HIV is budding from an infected cell, the cellular enzyme cyclophilin A binds to the capsid. 
%		On the surface of the capsid protein there is a loop with several proline amino acids, which is the bonding of cyclophilin.}\\
%	
%	The task which we gave to the users was to locate the following elements:
%	
%	\begin{enumerate}
%		\itemsep0em 
%		\item Capsid pentamer.
%		\item N-terminal and C-terminal domain of capsid protein.
%		\item Alpha helix in the N-terminal domain stabilizing the hexamers and pentamers.
%		\item Binding site of cyclophilin A.
%		\item Methionine amino acid within the alpha helix.
%	\end{enumerate}
%	
%	Each structure was located on a different scale. 
%	In the last task they were asked to find a Methionine amino acid molecule, for which they were given the chemical formula and a structural description.
%	The task of finding the pentamer was added so the users would practice moving the camera around. 
%	Pentamers and Hexamers share the same structure, they simply have 5 or 6 capsid proteins respectively. 
%	However, there are only 12 pentamers in the capsid.
%	Therefore, recognizing a pentamer was easier than actually finding one, because their sparcity was the largest obstacle in finding them.
%	
%	All capsid proteins, i.e., both hexamers and pentamers had the same color at the protein level. They could be distinguished only by shape. By zooming to the domain level, the N- and C-terminals are assigned different colors. At the secondary structure level, $\alpha$-helices and $\beta$-sheets received different colors. In the first study run, the helices had lower luminance than the domain they belonged to, and the sheets had higher luminance. In the second study run, each secondary structure received its own color. 
%	The cyclophiline binding site was not part of an $\alpha$-helix or $\beta$-sheet.
%	This was to test whether or not the user could find a structure that was not explicitly marked. 
%	We did not show the amino acid level.
%	To find the Methionine amino acid, the user had to look for a sulfur atom; there was no other amino acid with a sulfur atom near it, though there is a second one in the protein. 
%	If the user did not find the amino acid or realize that they needed to look for a sulfur atom, they were asked to find a sulfur atom instead.
%	
%	
%	
%	
%	
%	\subsection{Free Exploration}
%	In the structure identification task, we were interested in whether or not users could complete the tasks, as well as reasons for potential failures. 
%	In the exploration part, users could freely navigate through the visualization while thinking aloud. We were interested in the insights users would gain while exploring the model.
%	Most important is the degree of exploration, as well as what the users were capable of finding or looking at, as the users were capable of focusing on many different objects as well as on different levels.
%	
%	\subsection{Results of First Study Run}
%	\begin{table}
%		
%		\centering
%		\begin{tabular}{| c | c | c |}
%			\hline
%			Task \textbackslash User & 1 & 2  \\
%			\hline
%			Pentamer       & n & n \\
%			\hline
%			C-terminal     & y & y \\
%			\hline
%			N-terminal     & y & y \\
%			\hline
%			$\alpha$-helix & n & y \\
%			\hline
%			Binding site   & y & y\\
%			\hline
%			Methionine      & partially & y \\
%			\hline
%		\end{tabular}
%		
%		\caption{Results of Task One in First Study Run}
%		\label{table:tableIterationOne}		
%	\end{table}
%	
%	
%	Two users participated in the first study run. 
%	Their results can be seen in Table~\ref{table:tableIterationOne}.
%	In the first task neither found the pentamer. 
%	Both found the N and C terminals. 
%	Both found the Cyclophilin binding site. 
%	Only one found the alpha helix and the amino acid, while the other found a different sulfur atom.
%	
%	In task 2 neither user interacted significantly with the visualization. This was likely due camera control issues. 
%	One of the participants had trouble getting the camera to point where he wanted in general, the other at the lower levels.
%	This is partially due to the method of control over the camera. 
%	The controls allowed panning, zooming and rotating the camera. 
%	Furthermore, the movement of the camera did not take the semantic or zoom level into account.
%	
%	\subsection{Feedback}
%	Two issues were identified in the first study run. 
%	The first problem was camera control. 
%	In order to use the camera when zoomed further in a certain degree of experience was required, otherwise the camera could easily be moved too far.
%	In order to fix this, we altered the camera controls so the user could slow down the camera movement significantly.
%	
%	The other issue was the detection of the secondary structures. 
%	One of the users could not detect the $\alpha$-helices. The other could, but did not use the coloring of the secondary structure.
%	Instead, he looked at the correct area on the atomic level and found it based on the atomic structure.
%	We noticed that there were several helices and sheets in the protein. 
%	This meant that the altering of the luminance might not seperate a helix from the surrounding area. 
%	Therefore, we altered the coloring of the secondary structures to be based on hue, and each secondary structure would receive its own hue.
%	This coloring is based on the same principle as other levels.
%	
%	
%	\subsection{Results of Identification Task Second Study Run}
%	In the second study run, none of the users had significant issues with the camera, though some controlled it better than others.
%	For the 5 users, as shown in Table~\ref{table:seconrund}, the results are as follows:
%	\begin{table}
%		
%		\centering
%		\begin{tabular}{| c | c | c | c | c | c |}
%			\hline
%			Task \textbackslash User & 1 & 2 & 3 & 4 & 5 \\
%			\hline
%			Pentamer       & y & y & n & y & y\\
%			\hline
%			C-terminal     & y & y & n & y & y \\
%			\hline
%			N-terminal     & y & y & n & y & y  \\
%			\hline
%			$\alpha$-helix & y & y & n & y & y \\
%			\hline
%			Binding site   & y & y & y & y & y \\
%			\hline
%			Methionine      & y & partially & n & partially & n  \\
%			\hline
%		\end{tabular}
%		\caption{Results of Task One in Second Study Run}
%		\label{table:seconrund}
%	\end{table}
%	Apart from user 3, users could identify structures across all levels fairly well. 
%	Users 2 and 4 found a Methionine, but not the correct one. 
%	This is because they didn't notice the colors, so they didn't know exactly where to restrict their search.
%	Therefore, they found one of the other Methionine amino acids in the protein.
%	
%	
%	\subsection{Observations}
%	One of the users failed to identify the pentamer and mixed up the N and C terminals. 
%	In the capsid, there is some space between the hexamers. 
%	From the users description of the pentamer and of the capsid structure, he mixed up the interior and exterior of the hexamers. 
%	The user who considered a subset of the C-terminal as the entire domain had zoomed past the domain level to the secondary structure level.
%	The user in the second study run who did not find the $alpha$-helix also did not find a sulfur atom. He never zoomed in closely enough to the proteins to change the colors to the atom colors. It is likely that he became discouraged due to his failure to find the helix, as well as believing there was no way to identify the sulfur atom.
%	
%	With the exception of one user, the only problems with identifying structures came at the secondary structure and amino acid level. 
%	The amino acid level was significantly more difficult, as the amino acids were not explicitly visually represented. 
%	The users had to find it based on one atom, a strategy which they had to arrive at themselves. 
%	
%	
%	
%	\subsection{Results of Exploration Task Second Study Run}
%	
%	The actions of the users in the second task were extremely varied. 
%	Unlike the first study run, 4 of the 5 users spent time exploring the virus. 
%	However, the parts they explored varied significantly. 
%	
%	User 1 looked at the membrane and the proteins in the matrix. 
%	He found one of the capsid hexamers that can also be found in the matrix.
%	User 2 tried to find the other amino acids in the helix that had been mentioned in the description. 
%	He also took particular interest in the Cyclophilin binding site. 
%	He looked at its structure and identified several of the amino acids.
%	The third user, who had significant issues finding the structures, did not explore the HIV significantly.
%	The fourth user looked at the atomic structure of proteins that were not part of the capsid.
%	However he did not explore any protein in detail. 
%	Instead, he was more interested in the variety of proteins in the HIV.
%	The last user took interest in the membrane and the proteins near it.
%	He was interested in the structure of the protein and in the area where it met the membrane.
%	Of those who explored the virus, the users spent just short of 10 minutes on average for exploration.
%	
%	
%	
%	
%	\subsection{Feedback}
%	An interesting aspect was how little the users noticed the changing colors, yet still used the colors to identify the areas.
%	When asked about the changing colors in the post-experiment interview, all users noticed the changing colors when zooming to the atomic level, but only one noticed it on all levels, while a second thought something odd was occuring on the secondary structure level. 
%	
%	Still, every user that found the N and C terminals referred to them by their color. 
%	Several referred to alpha helices by color. 
%	This means that the visualization succeeded in creating a smooth transition between the levels, and was still useful, despite the users not being aware of its support. 
%	Furthermore, the fact that most participants were successful at least up to the secondary structure level indicates that our multiscale visualization technique can be used on each level. 
%	Overall, users liked the study and visualization, but thought the tasks were very difficult.
%	
%	
%	The largest difference between the study runs was the degree of exploration in the second task. In the first task, neither user explored the HIV extensively. In contrast, the users from the second study run explored the virus on different levels and areas. Likely this was affected significantly by the degree of control over the movement through the visualization. In the first study run, the users had significant control issues which were absent in the second study due to changes. In both study runs no users reported that they got lost or confused by the visualization.
%	
%	The users were also asked how useful they considered the visualization to be for their research, or what they could use it for. The users considered it useful for presenting their research and educating students, which is in line with our goal as mentioned in the beginning. However, only one user from the first study run considered it useful for his research. This is in a sense not surprising. Most users worked on the level of molecular structure or protein interactions. Furthermore, while it may be possible to visualize an entire virus, a physical simulation of one is a different problem. 
%	
%	
%	Several users expressed a desire for alternative representations that they were more familiar with, such as the cartoon/ribbon representation for secondary structures. However, there are two things to take into account. First, adding such representations directly would prohibit a smooth transition. Combining the ribbon representation together with the Van der Waals representation will lead to confusing images when between levels. Furthermore, it is possible to add additional representations on demand when the user asks for it. For example, the user could click on a molecule which could trigger a pop-up with alternative representations.
	
	
	
	
	
	
	%\subsection{feedback to implement into method}
	
	
	%\subsection{stuff they'd like to see}
	%- obviously they'd like everything.
	%- cartoon representation
	%- polarity etc.
	
	
	%\subsection{uses and applications}
	%
	%
	%We opted to perform a qualitative evaluation with XX biologists consisting of two blocks.
	%In the first block, users had to identify a set of pre-defined structures across multiple levels of scale in the HIV model. 
	%In the second block, users could freely explore the scene.
	%In both blocks, users were encouraged to think aloud. 
	%Sessions were observed by one to two study administrators, the screen was captured, and audio was recorded. 
	%The session was concluded by a questionnaire and an audio-recorded semi-structured interview. 
	%The task was provided by a professor of molecular biology and well-known illustrator of biological models. 
	%Users were first provided by a description of the HIV capsid protein, which is the single protein building up the HIV capsid.
	%Then they were asked to identify structures from this description in the HIV visualization, namely the capsid compartment itself, a special protein compound of the capsid, the two protein domains, secondary structures acting as binding sites, and a dedicated amino acid. 
	%The study was conducted on a (laptop specification, screen, color calibration). 
	%Users were sitting approximately ... cm from the screen, but were free to move. 
	%Before performing the actual study task, users were demonstrated how to navigate in the scene, and how to switch on and off certain sub-compartments. 
	%This was necessary so that all items were accessible without occlusions. 
	%We decided to perform a qualitative evaluation as our visualization is new, and there is currently no visualization that allows the user to look at all levels in a similar manner, so we do not have a method of comparison.
	%Our goal primarily was to see whether domain experts can identify the individual structures, whether this would be possible without color coding at all, and whether the view-dependent color assignment was irritating for them. 
	%
	%Users
	%The users were molecular biology students. As such, they had some but limited knowledge of the field [tbd may be variation]. 
	%As such, there needed to be an explanation of what they were looking for. The students ranged from x to y years studying.
	%
	%Results
	%-	How many students found the different targets
	%-	Insights
	%-	Probably need table of different types of insights.
	%-	Insights per minute  (ipm)
	%-	Answer to the questions we pose (table?)
	%-	People used
	%-	Number of people used
	%-	Describe type of study
	%-	Describe what this kind of study is.
	%-	Reference other (similar) studies
	%-	Argue why 
	%o	No baseline
	%o	No quantifiability (x in y seconds)
	%o	Want to measure usability
	
		
		
%	\section{Limitations}
%	There are still two basic limitations to our coloring scheme. 
%	The first is information on two different levels that are very close to each other, for example the amino acids and atoms. 
%	As can be seen in Figure~\ref{fig:hivScale}, some semantic scales are on similar or the same metric scale. 
%	This means the user will be approximately as far away from a molecule when he wants to see the atoms or amino acid information. 
%%	Amino acids vary significantly in size and complexity, however some consist out of just several carbon atoms with even less other atom types, except for hydrogen. 
%%	Serine for example has only 4 carbon atoms. This means the user will be approximately as far away from a molecule when he wants to see the atoms or amino acid information. 
%%	So the semantic scales reside on the same metric scale.
%%	Our visualization strategy is designed for distinguishing structures where each semantic level has a unique metric level.
%%	In other words, their semantic scales reside on the same metric level, as shown in Figure~\ref{fig:hivScale}.
%	The second problem is the variety of information. 
%%	For example, due to polarity, the electric charge may vary across a molecule. 
%%	Another interesting aspect of a protein might be hydrophobicity.
%	A researcher may want to specify what information he can see, such as polarity or hydrophobicity.
%	This means there are several paths that can be taken when zooming in.\\
%	Another problem is alternative representations, such as cartoon representations of the secondary structure of proteins, which are not being used.
%	These representations could cause unexplored issues when zooming from one level to another.
%%	Several users expressed a desire for alternative representations that they were more familiar with.
%%	However, there can be some difficulty when using them. The cartoon representation for example has a lot of area which can be seen through. 
%%	If two proteins are one behind the other, then they can be hard to tell apart.
%	

	
	
	
	\section{Conclusion and Future Work}
	The work presented here is a method that is capable of visualizing a hierarchical, cell-like structure on different levels in a coherent and cohesive manner using color. 
	The hierarchical structure of the coloring technique, along with the visibility based subtle variation in color allows users to navigate and inspect parts of the visualization without getting disorientated, while being subtle.
	Altering the color based on semantic zooming changes the meaning of color coding.
	Instead of discriminability for any situation, semantic color changes allow structures to be clustered or seperated as necessary.
	This is achieved while maintaining the connection between structures on different levels in a logical manner via the hierarchical nature of the coloring.
	Furthermore the coloring scheme is capable of showing structures on each level in a visually distinct manner. 
	The user study performed with our research prototype shows that experts can find information in an HIV dataset on each level, while not being distracted by the dynamic color mapping. 
	%\subsection{future work}
	
	While we demonstrated Chameleon on our HIV showcase with five zoom levels, we plan to extend our approach to more general use cases in the future -- in the biology domain and beyond.
	Currently, the hues of the overview level are initially assigned using a force-based layout and are sub-divided at lower hierarchy levels. 
	In the future, we plan to investigate methods with consistent hue assignments across all levels.
%	Another point is the visualization of multiple levels at the same time, which we did through luminance modulation.
%	However, it may be possible to encode more information without running the risk of creating salt and pepper noise.
%	There are several points that can be addressed in the future. 
%	First, we want to investigate mixing categorical and quantitative color coding on different zoom levels. 
%	A user may be interested not only in structural information, but also in attributes like polarity or hydrophobicity at certain zoom levels. 
%	This means there can be alternative paths in the color space when zooming in. 
%	Second, our study has shown limitations of structure identification tasks at certain zoom levels, where domain experts are used to different representations, such as the cartoon representation. 
%	A future challenge therefore is to find meaningful semantic zooming strategies that comprise both, the color and the structural representation. 
	
%	The most obvious is to overcome the limitations mentioned above. 
%	The users also expressed interest in interacting with the visualization. 
%	Structures such as the capsid consist out of numerous proteins. 
%	The users wanted to be able highlight individual proteins or sections. 
	%It might also be possible to couple this action with alternative representations for proteins, such as the cartoon representation.
%	Finally, camera control can be adapted to the visualization. 
%	Currently, the camera is controlled simply by inputing the desired direction of movement. 
%	Alternate controls, such as tying the camera to a protein or structure, could be added.
%	This would allow the user easier inspection of proteins or protein structures by making it easier for him to rotate around or follow the surface of an object.
	
	
	
	%% if specified like this the section will be committed in review mode
	\section*{Acknowledgments}
	The first two authors contributed equally.
		This project has been funded by the Vienna Science and Technology Fund
		(WWTF) through project VRG11-010 and supported by EC Marie Curie
		Career Integration Grant through project PCIG13-GA-2013-618680 and the 
		Austrian Science Fund FWF trough project T 752-N30.
	
	\bibliographystyle{eg-alpha}
%	\bibliographystyle{eg-alpha-doi}
	
	%%use following if all content of bibtex file should be shown
	%\no
	\bibliography{Chameleon}
\end{document}
