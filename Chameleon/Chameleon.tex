%\documentclass[journal]{vgtc}                % final (journal style)
\documentclass[review,journal]{vgtc}         % review (journal style)
%\documentclass[widereview]{vgtc}             % wide-spaced review
%\documentclass[preprint,journal]{vgtc}       % preprint (journal style)
%\documentclass[electronic,journal]{vgtc}     % electronic version, journal

%% Uncomment one of the lines above depending on where your paper is
%% in the conference process. ``review'' and ``widereview'' are for review
%% submission, ``preprint'' is for pre-publication, and the final version
%% doesn't use a specific qualifier. Further, ``electronic'' includes
%% hyperreferences for more convenient online viewing.

%% Please use one of the ``review'' options in combination with the
%% assigned online id (see below) ONLY if your paper uses a double blind
%% review process. Some conferences, like IEEE Vis and InfoVis, have NOT
%% in the past.

%% Please note that the use of figures other than the optional teaser is not permitted on the first page
%% of the journal version.  Figures should begin on the second page and be
%% in CMYK or Grey scale format, otherwise, colour shifting may occur
%% during the printing process.  Papers submitted with figures other than the optional teaser on the
%% first page will be refused.

%% These three lines bring in essential packages: ``mathptmx'' for Type 1
%% typefaces, ``graphicx'' for inclusion of EPS figures. and ``times''
%% for proper handling of the times font family.

\usepackage{mathptmx}
\usepackage{graphicx}
\usepackage{times}
\usepackage{epstopdf}
\usepackage{amsmath}

%% We encourage the use of mathptmx for consistent usage of times font
%% throughout the proceedings. However, if you encounter conflicts
%% with other math-related packages, you may want to disable it.

%% This turns references into clickable hyperlinks.
\usepackage[bookmarks,backref=true,linkcolor=black]{hyperref} %,colorlinks
\hypersetup{
  pdfauthor = {},
  pdftitle = {},
  pdfsubject = {},
  pdfkeywords = {},
  colorlinks=true,
  linkcolor= black,
  citecolor= black,
  pageanchor=true,
  urlcolor = black,
  plainpages = false,
  linktocpage
}

%% If you are submitting a paper to a conference for review with a double
%% blind reviewing process, please replace the value ``0'' below with your
%% OnlineID. Otherwise, you may safely leave it at ``0''.
\onlineid{153}

%% declare the category of your paper, only shown in review mode
\vgtccategory{Research}

%% allow for this line if you want the electronic option to work properly
\vgtcinsertpkg

%% In preprint mode you may define your own headline.
%\preprinttext{To appear in an IEEE VGTC sponsored conference.}

%% Paper title.

\title{Chameleon: Dynamic Color Mapping	for Multi-Scale Structural Biology Models}

%% This is how authors are specified in the journal style

%%% indicate IEEE Member or Student Member in form indicated below
\author{Nicholas Waldin}
%\author{Roy G. Biv, Ed Grimley, \textit{Member, IEEE}, and Martha Stewart}
%\authorfooter{
%%% insert punctuation at end of each item
%\item
% Roy G. Biv is with Starbucks Research. E-mail: roy.g.biv@aol.com.
%\item
% Ed Grimley is with Grimley Widgets, Inc.. E-mail: ed.grimley@aol.com.
%\item
% Martha Stewart is with Martha Stewart Enterprises at Microsoft
% Research. E-mail: martha.stewart@marthastewart.com.
%}

%other entries to be set up for journal
%\shortauthortitle{Biv \MakeLowercase{\textit{et al.}}: Global Illumination for Fun and Profit}
%\shortauthortitle{Firstauthor \MakeLowercase{\textit{et al.}}: Paper Title}

%% Abstract section.
\abstract{
Visualization of structural biology data uses color to categorize or separate dense structures into particular semantic units. 
In multiscale models of viruses or bacteria, there are atoms on the finest detail, aminoacids, secondary structures, macromolecules, up to the compartment level and all these levels can be visually distinguished by color.
However, currently only a single scale coloring schemes are utilized that show information for that particular scale only. 
We present a novel technology which adaptively, based on a current scale level, adjusts the color scheme to depict or distinguish the currently best visible structural information. 
We treat the color as a visual resource that is distributed given a particular demand. 
The changes of the color scheme are seamlessly interpolated between the color scheme from the previous views into a given new one. 
With such dynamic multi-scale color mapping we ensure that the viewer is able to distinguish structural detail that is shown to her on a given scale. 
This technique has been tested on subjects with an expertise in structural biology and has been overall well received.
} % end of abstract

%% Keywords that describe your work. Will show as 'Index Terms' in journal
%% please capitalize first letter and insert punctuation after last keyword
\keywords{Bla, Bla, Bla}

%% ACM Computing Classification System (CCS). 
%% See <http://www.acm.org/class/1998/> for details.
%% The ``\CCScat'' command takes four arguments.

\CCScatlist{ % not used in journal version
 \CCScat{K.6.1}{Management of Computing and Information Systems}%
{Project and People Management}{Life Cycle};
 \CCScat{K.7.m}{The Computing Profession}{Miscellaneous}{Ethics}
}

%% Uncomment below to include a teaser figure.
  \teaser{
 \centering
 \includegraphics[width=16cm]{Figures/Picture1.png}
  \caption{In the Clouds: Vancouver from Cypress Mountain.}
  }

%% Uncomment below to disable the manuscript note
\renewcommand{\manuscriptnotetxt}{}

%% Copyright space is enabled by default as required by guidelines.
%% It is disabled by the 'review' option or via the following command:
% \nocopyrightspace

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%% START OF THE PAPER %%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

%% The ``\maketitle'' command must be the first command after the
%% ``\begin{document}'' command. It prepares and prints the title block.

%% the only exception to this rule is the \firstsection command
\firstsection{Introduction}
\maketitle

With improving technology, more and more data across all levels - from atomic to compartment - is being gathered on Viruses and Cells. 
Improving computing technology makes it possible to display an ever increasing amount of this data at once, up to and beyond an entire HI virus~\cite{muzic2015cellview}, with its complete macromolecular composition.
This allows all levels to be present in a visualization; we can start at the compartment level and zoom in past the proteins, their domains and secondary structures, such as $\alpha$-helices and $\beta$-sheets, all the way to the amino acids and atoms.
Unfortunately, a simplistic visualization of these levels will lead either to a loss or excess of information.
For example, if we base the visualization on proteins, then the information on secondary structures and atoms is lost. 
If we base the visualization on atoms or secondary structures, any zoomed out view will simply see salt and pepper noise. 
A naive visualization that transitions from one level to the next as the user zooms in may at first glance seem sufficient.
However, there are several issues that pop up.
First, the transition may be appear chaotic, as the visualization may change quickly.
This will not only affect understanding how two levels are connected, but also the comprehension if the user is between levels.
Second, there is a loss of information when transitioning from one level to the next. 
For example, if a user is looking at two compartments that are next to each other and zooms in where they meet, then the information where one compartment ends and the other starts is lost. 
The user would be capable of comprehending the proteins individually, but not their relationship to each other.
Furthermore, this continues through to the lower levels. 
The reason for this loss is the inherent hierarchy of the data.
An atom belongs to an amino acid, which in turn belongs to a domain of a protein, all the way to the top.
Therefore, a visualization of the data must fulfill two requirements. 
One, the transtion from one level to another must be smooth.
Two, the inherent hierarchy of the data must be preserved.
This hierarchy lends itself easily to a tree structure.
One way to assign information to this tree is to place it into a color space.
For example, a tree could be constructed where each branch has its own hue.
As the tree goes down through the structure of the cell, the hues become subdivided.
A compartment could be red, the proteins different shades of red, and so forth.
However, such a simple approach scales poorly. 
There can be dozens if not hundreds of different proteins, not to mention the amount of domains or secondary structures.
As such, the lower levels will certainly become indistinguishable.
It might appear to be a good idea to branch out into luminance and saturation.
However, this means that the tree expands into three different dimensions.
This can cause issues when understanding the data.
Varying hue, saturation and luminance all at once can easily lead to cognitive overload, as it is difficult to operate in three dimensions at once. 
Furthermore, in an illuminated or shaded scene, two objects with the same hue but different luminance that are next to each other might be misconstrued as just one object, with the varying luminance userstood as changing structure. 
As such, there are significant perceptual and cognitive restrictions placed on color coding. 

We propose a semantic zooming method for a multi-scale visualization of a cell or virus-like structure, based on a view-dependent, hierarchical color scheme.
Starting from the highest level, we progressively free-up unused color space and redistribute it to visible elements defined by the current zoom level and item visibility.
In the HIV example (refer to teaser image), the user initially sees the different compartments. 
As the user zooms in, the proteins receive more distinct colors based on which compartment they are in. 
As compartments and proteins disappear, the colors of the visible proteins are adjusted to enhance discernibility.  
As the viewer zooms further in, the domains of the proteins will become distinct, then the secondary structures, and eventually even the atoms, whose colors are predefined by convention. 


%One realm in which this system can be supported in is color. 
%Color has been consistently and effectively used to seperate objects and sections from each other, and can also be used to display information about the object at the same time. 
%Therefore, it would be advantageous to use these benefits in such a system. 
%However, there are significant challenges in doing so. 
%First, there are not that many easily distinguishable hues. 
%For example, with constant luminance and chroma, the just noticeable distance - the distance between two colors where the a human can distinguish them - is equal to N degrees, based on a distance of 2.3~\cite{mahy1994evaluation}. 
%However, this is of course not enough to be easily distinguishable. If 10 times the just noticeable distance were used, we would only have N colors. 
%Furthermore, if we subdivde the colors when zooming in, similar to a tree, then the discriminability becomes worse with each leve. 
%Certainly, it is possible to branch out into saturation and luminance as well. 
%However, varying hue, saturation and luminance all at once can easily lead to cognitive overload, as it is difficult to operate in three dimensions at once. 
%Lastly, in an illuminated or shaded scene, two objects with the same hue but different luminance that are next to each other might be misconstrued as just one object, with the luminance being used to indicate structure. 
%As such, there are significant perceptual and cognitive restrictions placed on color coding. 






%from here old \newline
%Biological organisms can be viewed on different scales. 
%For example, the human body consists of organs, cells, proteins and molecules. As more detailed data is becoming available across all levels, it is possible to combine visualizations of multiple scale levels into a single integrated visual environment. 
%This poses new challenges for visualization experts, including seamlessly adapting the levels of detail of structural representations for real-time rendering, .... (experts, please address the challenges).
%
%A challenge which has not been addressed so far is color-coding. Consider, for instance, the human immunodeficiency virus (HIV).
%To understand its viral lifecycle, researchers are investigating the shape of its compartments, the role of the individual proteins in viral replication, the secondary structures, as well as structural properties of binding sites on the atomic level. 
%Traditionally, researchers use dedicated visual representations for each level of scale, and illustrators provide hand-crafted visualizations to communicate new findings to the general public. 
%Each of these scale levels uses a distinct color coding so that observers are able to distinguish and identify the structures. Can we show existing examples here? 
%When integrating multiple scales into a single zoomable visualization, it is therefore necessary to not only provide a seamless structural zooming, but also a color-coding mechanism that takes the current level of detail into account. 
%While successively providing more levels of detail of the structures when zooming in, we are severely limited in the number of available colors due to perceptual constraints and limitations of the monitor hardware. 
%
%We propose a semantic zooming method for visualizing color-coded a virusmulti-scale visualization based on a view- dependent hierarchical color-scheme. 
%Starting from the lowest zoom-level, we iteratively split up the available color space to the number of necessary colors defined by the current zoom level and item visibility.
% Our method thereby trades discriminability of individual elements against temporal coherence. 
%In the HIV example (refer to teaser image), the user initially sees the different compartments. 
%As the user zooms in, the proteins receive more distinct colors based on which compartment they are in. As compartments and proteins disappear, the colors of the visible proteins are adjusted to enhance discernibility.  
%As the viewer zooms further in, the domains of the proteins will become distinct, and eventually even the atoms, whose colors are predefined by convention. 

\section{Related Work}

We divide the related work in two sections, in the first section we cover previous work about appropriate usage of colors in visualization, and their perceptual impact. 
In the second section we cover related work about large scale molecular rendering, to which we build our technique upon.

\subsection{Colors in Visualization}

A mapping from data to color is the same as selecting a color map for the data. 
The structure of the color map depends heavily on the visualization goal. 
N
Not only clear visibility, but also harmonious and appealing colors can be important~\cite{ihaka2003colour}, as well as the assignment and mixing of colors~\cite{wang2008color}. 
There are many points to consider, and as a result guides and guidelines have been published on how to decide which color scheme is the most appropriate~\cite{bergman1995rule}, \cite{healey1996choosing}, \cite{bernard2015survey}, \cite{steiger2015explorative}.

Furthermore, several tools have been developed to assist users select appropriate color maps, such as colorbrewer~\cite{harrower2003colorbrewer}, or "i want hue"~\cite{iwanthue} and XCluSim~\cite{l2015xclusim} which generate colors for clusters of data. 

Such clustering can, however, cause perceptual issues, either due to the large number of clusters or their layout. 
Particular care needs to be taken when dealing with higher dimensional data~\cite{mittelstiidt2014revisiting}, so the distances between the clusters do not become distorted. 
Furthermore, in cases such as coloring maps, visually dominant structures may visually suppress small groups or areas~\cite{lee2013perceptually}.
Visualization of information such as can be found on maps can lead to small areas being next to much larger ones. 
In this case, it may be difficult to spot the small areas, and lowering the saturation of the larger areas allows the small ones to stand out more.
Recognition may also be affected by contrast effects which may need to be dealt with~\cite{mittelstadt2014methods}. 


XCluSim’s uses a tree-based method~\cite{tennekes2014tree} that attempts to overcome these issues in the case of hierarchical structures. 
The tree method uses HCL space – a cylindrical coordinate version of CIELab with Hue , Chroma (Saturation), and Luminance – and gives each cluster a different hue. 
The root of the tree has no saturation, i.e. grey, and the hue is divided up into different wedges, one for each branch, with some space cut out between branches, in order for there to be a jump in color from one wedge to another. 
As the tree spreads out, the saturation of the nodes increases, and each level gets its own smaller wedge. 
Essentially, each level has its own hue circle with a defined saturation. 
However, this method can fall apart if the data becomes too large. Each node in the tree has it's own hue. 
As the tree grows, the hue of the nodes becomes more similar. 
Either the tree can not grow more because the minimum hue distance between nodes is reach, i.e. the distance between wedges, or the nodes are so similar they become indistinguishable. 
In contrast, our method allows for dynamical increasing and decreasing of wedge angles based on visibility and depth, allowing for overlap to occur at the lower levels. 
If some of our branch's nodes are not visible, then the wedge will shrink, allowing neighbouring branches to expand. 
This assists color discernment by the user when looking at the objects of a subset of the branches.
As mentioned, we also allow the branch to expand at lower levels.
Our visualization deals with numerous different low level structure. 
Using~\cite{tennekes2014tree} results in the lower level structures being indistinguishable. 
As such, a certain amount of overlap is allowed at certain levels, because the users focus at these levels is on an object or subsection thereof. 
Further details can be found in Section ~\ref{Overview}.

%Color maps are used often in visualization. Their structure depends heavily on the application, as has been shown in [Colour for Presentation Graphics], [Color Design for Illustrative Visualization]. Several tools have been developed 
%
%Color maps are used often in visualization. 
%Their structure depends heavily on the application, as has been shown in [Colour for Presentation Graphics], [Color Design for Illustrative Visualization], 
%
%A Rule-based Tool for Assisting Colormap Selection, http://ultra.sdk.free.fr/docs/Image/Colors/ARule-basedToolfo0AssistingColormapSelection.htm], [Choosing Effective Colours for Data Visualization], 
%[a survey and task-based quality assessment of static 2d colormaps], [explorative analysis of 2d color maps]. 
%Several tools have been developed to assist users select appropriate color maps, such as colorbrewer, or iwanthue, [http://tools.medialab.sciences-po.fr/iwanthue/] and XCluSim, which are aimed at generating colors for clusters of data. 
%However, when dealing with numerous clusters, special attention must be paid to the perceptual qualities of the color map


%\subsection{multiscale view}
%Sometimes hierarchical data can also be viewed on multiple levels at once, for example a protein can be viewed on the overall structure as well as on the atomic structure~\cite{kauker2013rendering}. 
%Alternatively, distortions of the object or different rendering levels in different areas of the camera may be used. 
%For example, in~\cite{hsu2011rendering} the area in the center of the camera is rendered as closer in. 
%This is achieved through using non-linearly bent camera rays and multiple cameras. 
%Parts of the object can also be distorted, for example by widgets such as in~\cite{sudarsanam2008non}, where local areas are distorted using non-linear perspectives. 
%Alternatively, the user might want to zoom into a structure. An example of this is~\cite{artignan2009multiscale} in which a large hierarchical graph is visualized.
%The graph has a large depth, and to investigate certain nodes the user must zoom in. During this, the node expands and changes color while its children become exposed. 
%This is recursively applied down the branch, allowing for an arbitrarily deep descent.

\subsection{Multi-Scale Molecular Visualization}

The development of new modelling techniques for three dimensional molecular structures led to an rapid increase in size of the studied datasets.
To keep up with the progress, new visualization methods were specifically developed to address this challenge.
Ove Daae Lampe et al.\cite{lampe2007two} pioneered real-time rendering of large-scale atomic data on consumer level hardware. 
They extended the fast billboard-based approach introduced by QuteMol \cite{tarini2006ambient}, by rendering the structures per residues rather than per atom, thus reducing the memory bandwidth usage and the GPU driver overhead. 
Lindow et al. \cite{lindow2012interactive} followed-up by using  instanced rendering to draw entire structures instead.
For each molecule type, they generate 3D grid of the atoms which is stored on the GPU, and then ray-casted upon rendering.
Falk et al. \cite{falk2013atomistic} further refined the method with improved depth culling and hierarchical ray casting to achieve faster rendering performance for even larger scenes. 

Parulek et al.\cite{parulek2014continuous} introduced seamless transitions between different levels of coarseness for the representation of the molecular surface based on the distance from the camera.
The goal was not only to reduce the computation cost, but also to utilize the shape as a mean to reduce high-level details and noise when observing the structure in its entirety.
Their technique is using real-time ray-tracing and offers high quality surface details, but it does not scale well in terms of performance when compared to atom-based rendering methods.
A novel approach, for real-time rendering of structures with up to tens of billion atoms, was later on introduced by Le Muzic et al. \cite{le2014illustrative}. 
Their approach, also based on level-of-detail, uses tessellation shaders to switch between different degrees of coarseness for the molecular structures, on-the-fly and upon the rendering operation.
The entire scene is thus rendered efficiently in a single draw call, approaching zero GPU-driver overhead. 
As a follow up, they developed and released cellVIEW \cite{muzic2015cellview}, a tool designed for rendering large-scale molecular scenes, which was implemented with Unity3D, a popular 3D engine.
cellVIEW was primarily developed to showcase large molecular structures generated with cellPACK \cite{johnson2015cellpack}, a tool developed to procedurally generate accurate and multi-scale models of entire viruses and cells.

The Chameleon is built-upon cellVIEW, and is an attempt to improve understanding upon exploration of multi-scale molecular scenes generated with cellPACK.
cellVIEW leverages GPU computing and parallel programming to enable real-time rendering and therefore, the Chameleon was developed with the same programming paradigm.


\begin{figure*}[t]
	\centering
	\includegraphics[width=0.85\linewidth]{Figures/coloroverview}
	\caption{Overview of our dynamic and hierarchical color scheme. (1) The first two levels of the hierarchy, in this example we have four groups and a total of 20 different protein types, (2) The current viewport, the red square represents a close-up view, (3) The visibility information is extracted from the current viewport, (4) The color palette is updated to prioritize visible elements only.}
	\label{fig:coloroverview}
\end{figure*}

\section{Overview}
\label{Overview}


Mesoscale datasets feature many relevant properties which are present at different scale levels.
The molecular properties that we provide in this work are, from top to bottom: Compartment (or group), protein type, protein domain, secondary structure and atom type.
We opted for these properties because, according to domain experts, they are the most relevant properties in visual analysis of three dimensional molecular structures.

%This information is internally declared and accessible for each single rendered atom, which allows us to perform dynamic coloring

Our goal is to provide a solution that would automatically display meaningful information at all zoom levels.
This information should also be coherent between levels.
To provide smooth and logical transitions across level we use a hierarchical color coding approach inspired from \cite{tennekes2014tree}.
Based on perceptual reasoning, we use isoluminant colors, and we choose to only vary the hue channel to generate the color palette. 

On the first level of the hierarchy, we first assign portions of the hue circle to each group of protein types.
Protein types of a given group are then given a unique hue value on the corresponding arc, as shown in Figure \ref{fig:coloroverview}.
In the initial state, the size of the hue arcs is set according to the number of protein types contained in each group. 
Spacing between hue values of neighbour protein types of the same group is proportional to the number of type per group and the size of the arc. 

Due to the large difference in terms of size between compartments and protein, it is very likely that several compartments will be less or no longer be visible as we zooming-in on a single protein. 
Based on this principle we update the color palette on-the-fly based on visibility information which we extract from the previous rendered frame.
For each protein type, we compute the percentage of visible elements, as well as the screen coverage in pixels for displayed proteins.
We sum up those properties for all the protein types of a group to deduce a weighting coefficient which is then used to scale the size of the hue arcs of the groups.

When zooming further in, we progressively start to reveal colors of the underlying protein properties, such as the chains, or secondary structures.
For coloring the subsequent levels we sample hue values around the hue of their parent as shown in figure X \ref{noref}.
We use pre-defined camera distance thresholds to determine when to transit to the next level.
To ensure a smooth transition, the hue distance between the parent and the children is progressively scaled until reaching a pre-determined offset value.
%In the case of protein types, the coloring mechanism allows to enlarge the size of the hue arcs while ensuring no overlap between neighbooring groups. 
%However, when displaying other properties it would be more challenging to reuse the same principle, because of ** TODO REASONS **.
To ensure a minimum degree of overlapping hue ranges between two neighbours, we use a focus + context to reduce occurence of recurrent colors in the background.

Atoms constitute the final level of our hierarchy.
In molecular visualization this information is commonly associated with predefined colors also called CPK coloring.
To transit to this final level we perform linear color interpolation in RGB space, between the color from the previous level (secondary structures) and final atom color.
The coefficient of interpolation is defined according to the camera distance and pre-defined distance values *** MANU'S MAGIC COLOR INTERPOLATION HERE ? ***.

%\textbf{. With a static hierarchical color coding approach, the hue arcs are predefined on the highest level, and multiple colors are then generated for the lower levels by manipulating channels like chroma luminance} \\
%
%\textbf{. The strictly static approach has two limitations:}
%
%\textbf{. It uses luminance variation to generate distinct colors, which is not preferable to use with a lit 3D environment} \\
%
%\textbf{. Hue arcs are statically defined, therefore, in case the entire wheel is occupied, colors generated inside the wedge do not have an optimum degree of discriminability.  } \\
%
%\textbf{. Indeed, HUE is such a stronger cue to differentiate between types** add better justification **}
%
%\textbf{. Therefore we suggest a method to define color coding hierarchically, where the initial hue value would no longer be statically defined }. \\

%\textbf{. The principle is to use the view information to enlarge to interact with the size of the hue arcs on the highest zoom level.} \\
%
%\textbf{. A naive approach would be to simply increase the hue arcs as the camera gets closer to an element and to interpolate between levels based on the distance. }
%
%\textbf{. However, by increasing the arc lengths arbitrarily we will inevitably run into a case where two consequent segments would overlap } \\
%
%\textbf{. This shall be avoided when possible in order to ensure a maximum level of clarity } \\
%
%
%\textbf{. We address this problem differently based on the zooming level, via two different approaches} \\
%
%\textbf{. Indeed, in mesoscale datasets, the multiple semantic levels from entire viruses or cells, down to single atoms, are not evenly spaced.} \\
%
%\textbf{ . **TODO** ruler figure with all the scales}
%
%
%\textbf{By observing the scale we realize that the size difference between levels beneath the protein levels is much lower than the levels above.} \\


%\section{Details Info Dump}
%
%full sentences are commented in the tex
%\textbf{. Molecules have multi-scale properties which can all be characterized by color } \\
%
%%.The scenes that we are displaying represent meso-scale biological structures and comprise a large number of molecules (proteins or lipids).
%%.Each protein carry essential properties that is used to convey a different information for each single scale (TODO: Do a figure to explain).
%%.Each of these properties can be visualized and highlighted using a specific color coding.
%
%\textbf{. Molecules have Bottom-Up properties, type and group} \\
%
%%. Molecules can be of different species or type, which characterize their structure.
%%. A group of molecules with similar structures is referred as instances of type X.
%%. Types are also categorized in groups, based on their location or function. 
%
%\textbf{. Molecules have Top-Down properties, domain, secondary structures, and atom type} \\
%
%%. Each molecule comprise a set of atomic particles.
%%. Atoms have different types, C, H, O, N,...
%%. Atoms are assembled in groups to form the amino-acids.
%%. Amino-acids are chained and form segments of amino-acids that are characterized by their shape such helices and sheets, this is called the secondary structure.
%%. The secondary structures are grouped together and divide the proteins in different domains.
%
%\textbf{. BOTTOM-UP PROPERTIES} \\
%
%\textbf{. We use hierarchical color assignments for Bottom-Up properties (we defined wedges in the color wheel for the groups and types inside a group are assigned a color in the corresponding wedge )} \\
%
%%. We decide to chose iso-luminant colors (for aesthetic reasons).
%%. We first assign a wedge of the color-wheel for each group.
%%. In the initial state, the size of the wedge is proportional to the size of the group in terms of protein types.
%%. The colors of the protein are defined accordingly to the color of their group (hierarchical).
%%. Only the hue differs between different types of molecules
%%. Inside a wedge each protein type of a group is assigned to a portion of the wedge with equal spacing between two protein types.
%%. Should a wedge be enlarged or shrunken, the color assignment is set relatively to the size of wedge.
%
%\textbf{. Static tree color maps offers limited discrimination for a large number of colors because it uses other properties to vary colors inside a wedge, HUE IS A MUCH STRONGER CUE} \\
%
%%.The hue circle is limited (360), therefore with several groups comprising tens of individual types we will quickly run out of colors.
%%.In the tree-color paper they solve this problem by generating more colors for each wedge using the additional channels (chroma \& luminance).
%%. This approach has a poor potential for discrimination between different properties since inside a predefined inside a wege colors will still remain rather similar. 
%
%\textbf{. NAIVE APPROACH: Grow the size of color wedges dynamically when zooming in to vary the hue of the colors inside a wedge} \\
%
%%. Rather than using different channels like luminance and chroma we want to keep discriminating colors with HUE because it is such a strong cue.
%%. In order to keep using the hue to discriminate between colors the size of the wedges must be scale according to the zooming distance.
%%. However as the wedges grow their is no mechanism that would prevent two neighbour wedges to overlap which could results in misleading coloring choice.
%
%\textbf{. Wedges may overlap, solution is to use visibility information to control the scaling of the wedges} \\
%
%%. Rather than scaling the wedges according to the zooming distance we suggest to grow or shrink the wedges according to what is currently visible in the current viewport.
%%. For example, if all molecule groups are equally visible, the size of their wedges will be proportional to the size of the groups in terms of protein species.
%%. If a protein group is partially visible or not-visible at all, the corresponding wedge will be scaled accordingly, thus freeing space in the color wheel for other wedges to grown
%%. [Make figure to show example]
%
%\textbf{. Read Visibility Information must be read form the current viewport} \\
%
%%.We analyse visibility information from the rendered frame to check which molecules types are actually currently visible.
%%.The visibility information we use is screen coverage and number of visible instances.
%%.The number of visible protein can be low, while few molecule can have a large screen pixels coverage if located close to the camera.
%%.Similarly the screen coverage can be low while a large number of molecules may still be visible, if camera is looking a the scene from far away.
%
%\textbf{. Use Visibility Information to control the sizes and the layout of wedges, via force fields} \\
%
%%. Once we have the visibility information for each species we evaluate the weight of the species group for scaling the wedge.
%%. We use a force based layout to arrange the wedges along the color wheel.
%%. Each wedge comprise a centroid that can move either left of right, in one dimension.
%%%. The position is then mapped from 1D to a 2D circle for debugging.
%%. Each wedge acts as a circular force field centred around the centroid and which pushed the other wedges away.
%%. The radius to force field is proportional to the size of the group, the number of visible instances, and the percentage of pixels that are occupied by instances of the group.
%%. The radius of the force field is computed as follows: write formula here.
%%. The integration of the forces is computed as follows: write integration formula here.
%%. To make sure that wedge centroids are not pushed away too much from their original location and are shifting in color too much we also apply attraction forces from the centroids to their original location
%
%
%\textbf{. TOP-DOWN PROPERTIES} \\
%
%\textbf{. To transition between two down properties we rely mostly on the camera distance rather than the visibility information} \\
%
%\textbf{. We use HUE again as a cue to discriminate between sub-domains of a protein} \\
%
%\textbf{. We chose HUE values for the chains that are located in the vicinity of the Protein HUE value} \\
%
%\textbf{. We perform smooth transition between protein HUE and terminal HUE chain as the viewer zoom-in} \\
%
%\textbf{. When focusing on proteins to observe the chains, the chain HUE values of neighbouring or likely to cross/overlap those of the focus} \\
%
%\textbf{. We came up with the idea to prioritize the display of chain properties to proteins with a high screen coverage} \\
%
%\textbf{. Additionally when zooming closely to a protein to observe bottom-up properties, we desaturate proteins with low screen coverage to reduce clutter cause by the display of too many top-down property colors for context molecules } \\ 
%
%
%\textbf{At the finest zoom-level we show the atom colours, these colors follow bio-chemical standard and are therefore predifined. } \\
%
%\textbf{We perform color smooth color interpolation between the current color of the atoms and their terminal colors. } \\
%	
%\textbf{To improve the bla-bla, we use the interpolation technique by Manu which constists of bla-bla-bla} \\

\section{Dynamic Color Palette}
\label{sec:dynamic_color_palette}

We use information about the visibility of the rendered protein to optimize the color palette for a given viewport.
For each group of protein types, we analyse the visibility factor of their protein types and we derive a weighting coefficient which we use to scale the corresponding sections of the hue circle.
The visibility factor of protein type is determined by two parameters.
The first one is the screen-coverage in pixels of all the protein of the given types.
The second parameter is the percentage of protein of a given type that are actually visible in the rendered image. \\

It is important to take into account the screen coverage and not only the number of visible elements.
Indeed, a given protein type may have a low number of visible proteins but the visible ones, may still occupy a large portion of the screen when closely located next to the camera.
In this particular case we want to ensure that this element will weight equally in the computation of the overall group coefficient.
The visibility factor of a given protein type is computed a follow:

\begin{equation}
c_{i}=\begin{cases}
1, & \text{if $p_{i}<t_{p}$ and $v_{i}<t_{v}$}.\\
0, & \text{otherwise}.
\end{cases}
\end{equation}

\begin{equation}
C = \left\lbrace c_{1}, ... , c_{n} \right\rbrace 
\end{equation}

Where $c$ corresponds to the visibility factor of a given protein type $i$, $p$ corresponds to the percentage of pixels occupied by proteins of type $i$, and $v$ is the percentage of proteins of type $i$ that are visible.
$t_{p}$ and $t_{v}$ correspond to arbitrarily defined thresholds for the screen coverage and visibility, respectively. 
$C$ is a set of $n$ protein types that constitute a group.
For that given group the weight coefficient is computed as follows:

\begin{equation}
w = \frac{\sum_{i=1}^{n} c_{i}}{n} s, c_{i} \in C
\end{equation}

Where $w$ is the weight of the group, and s is a scaling factor which is proportional to the number of protein type in that group. \\

We leverage GPU computing in a post-processing operation in order to compute the visibility factors of each protein type efficiently.
Upon rendering we generate two additional off-line textures which contain for each pixels the atom and protein unique identifiers, respectively.
We priorly declare a two GPU buffers which will, for each protein type, store the occupied pixel count and the total number of visible proteins, respectively.
Subsequently, in a dedicated compute shader, we browse through all the pixel of the protein IDs and we increment the pixel counter corresponding to the protein type stored in the video memory.
At the same time we also flag, in a dedicated GPU buffer, the proteins are present in the generated texture.
This information will allow us to count the visible instances of a given type.
In a second pass and in a dedicated compute shader, we then browse through all the protein instances.
For each protein which was flag as visible in the previous pass, we increase the number of visible instances corresponding to the protein type.
Since the computation is done in parallel it is important to use atomic intrisinc function to increment the counters in order to avoid concurrent access to the same value from two different threads.

\section{Force-Based Compartment Layout}

Once we determine the weight of a group, one remaining task is to position groups on the hue circle.
A naive approach would be to start positioning a first group on the circle, and to place the remaining groups subsequently on the circle, given the size of each group.
While the position of the first group on the hue circle can be arbitrarily defined with this approach, the other groups are not guaranteed to be located as near as possible to their original location.
This could lead to overly large hue shifts for the centroid of the groups.

To avoid this issue we propose a force-based layout for the positioning of the group centroids on the hue circle.
The forces are applied in a single dimension which corresponds to the hue, and include distance constraints between the groups, as well as attraction forces between groups and their original position.
We then integrate the forces, using a Euler Integration to compute the new positions of the groups until reaching a state of equilibrium.
For a given group $i$, the distance constraint response force with another group $j$ is computed as follows:

\begin{equation}
y(i, j) = d(g_{i},g_{j})max(|g_{i} - g_{j}| - (r_{i}+r_{j}), 0)
\end{equation}

Where $d$ corresponds to the sign, or direction of the response, g is the position of the group centroid, and r is the radius of the distance constraint and which corresponds to the weight computer from the visibility information and described in Section\ref{sec:dynamic_color_palette}.
For a single group the overall forces, comprising attraction and repulsion forces are computed as follow:

\begin{equation}
f_{i} = (g_{i} - i_{i}) + \sum_{j=1}^{n, i \neq j} y(i,j)
\end{equation}

The first part of the right side of this equation correspond to the attraction forces, where i correspond to the initial group position.
The second part is the sum of repulsion forces between the given group and the other ones.
Additionally we also include a damping value in the integration calculus to smooth-out the motion of the group centroids when the viewport and the visibility configuration is abruptly changing.

\section{Implementation}

Mathieu write low-level implementation details here.

%.Upon rendering we also render an off-line texture where each pixel contains the atom and instance ID to which the rendered atoms correspond to.
%
%.The ID is used to fetch atom meta-data in a post-processing shader, which is then used to keep track of visibility information.
%
%.First we gather information about the visibility of the protein types:
%
%.We define a number for each protein type which acts a counter to for the number of visible instances.
%
%.For each pixel we first update a flag corresponding to the protein instance to specify that this element is visible.
%
%.We analyse the result of the previous rendered frame and gather visibility information in real-time.
%
%.Upon rendering 



%\section{Technique (section written by Nicholas)}
%
%When applying a coloring scheme to data of this type, several things need to be taken into account. 
%First, the representation should support the level the user is looking at, e.g. not show the protein domains when the user is looking at the compartment level. 
%Second, switching from one level to another should not be confusing.
%Third, the user should be able to easily identify useful information at the level he is looking at. 
%Because predetermining all the colors for each item in the scene and not allowing for view dependency will, with enough data, guarantee that data points will become indistinguishable. 
%Fourth, the coloring must allow the user remain orientated and determine what belongs to the stuff he is interested in. 
%For example, he needs to know where a compartment ends and the next one begins.
%Stress the fact that temporal coherence and discriminability by color are contradicting each other if we need a lot of colors (give numbers for HIV!). 
%Ware (?) points out that luminance is more useful for encoding high-frequency information, while hue is easier to interpret for encoding low-frequency information. 
%
%This is also reflected in the well-known ColorBrewer color schemes, where colors of categorical palettes differ primarily by hue, while quantitative color schemes operate mostly on luminance level.  
%We therefore use utilize the HCL color space that separates these two properties into different dimensions (luminance is the vertical axis, while hue and chroma are represented on the perpendicular planes as polar coordinates). 
%Another useful aspect of the HCL color space is that it is simply an alternative representation of the CIEL*a*b* color space and therefore perceptually linear. 
%This means that we can linearly link changes in the color space to perceptual responses. 
%We start by assigning each item on the lowest LOD a distinct hue. 
%Since the lowest hierarchy level comprises the entire model, this assignment is static and does not change with the viewing angle. 
%Given the number of elements $n$ on the lowest LOD, the desired luminance and chroma, the hue of the i’th element is simply defined by $h_i=i*360/n$. 
%This results in $n$ isoluminant colors with equidistant hues. 
%(Chroma is luminance-depending if we consider the sRGB boundaries, but we don’t do this now!)
%We use a hue circle here, but any parametric curve within the HCL space could be used. 
%In this case, the colors would not be isoluminant, but still equidistant in the perceptually linear color space. 
%Each section applies force on its neighbouring section, proportional to the number of different kinds of proteins that are visible. 
%This means that the section can grow and shrink, depending on visibility. If a compartment is not visible, then the section shrinks to a size zero. 
%
%However, a degree of consistency is still desired. It would be unwanted for a compartment to switch over to the opposite color, such as blue to yellow.  
%As such something needs to be in place to keep compartments from moving too far.
%The switch to the proteins color occurs when the distance is greater than 5*2.3 =5*jnd in cielab space [Mahy 94 evaluation after adoption]. 
%This is equal to an angle of X on the hue circle.
%
%Another problem is how do we choose the colors for the domains? Their color needs to be view dependent as well as near to the color of the protein they belong to. 
%The color of the chains does not Interact with the color of the other proteins, but does if they are showing their chains. 
%Whether or not the chains are shown depends on the how close the camera is to the protein, unless the color distance would be below a certain amount (5*2.3) (8.8 degrees). 
%The hue circle is reused to show the colors of the chains. See fig[]. 
%The chains don’t cause any force on the proteins, and the proteins cause no force on the chains. 
%The chains of two different proteins can cause force on one another if they are being shown. 
%Because the chains would normally surround the entire circle, they only push each other away to a maximum distance of X. 
%This allows for the chains to have similar colors to the proteins.

\section{User study}
A user study using the HIV virus as a data set was performed in order to test our visualization and to improve it based on the feedback.
The user study was conducted in two interations. 
In the first iteration, two domain experts tested the software. 
Their feedback was used to adapt the software, which was then tested by 5 domain experts.
No information about our visualization method was revealed to them. They only knew that the HIV virus was being visualized.
In the first iteration the secondary structures were identifiable through luminance, not color. They had the same hue as the domain they belonged to, simply lighter ($\beta$-sheets) or darker ($\alpha$-helices);

\subsection{users}
As we wanted to evaluate the use of our visualization for research purposes, we gathered 7 domain experts. 
6 were PhD. and postdocs, one was a master student, all in the field of molecular biology. 
In order to conduct their research, the participants use visualizations on the protein or molecular level.


\subsection{how was the study designed}
In user studies, it is common to give the user one or more simple tasks which must be solved. 
The time it takes the user to solve this task is measured and statistically analyzed. 
However, this doesn't function well with our study. 
Rather than simply giving the user one or more simple, specific tasks and measuring how quickly he could solve them, we opted to use a qualitative study~\cite{gomez2014insight}. 
In this kind of study, the amount and type of information the user can find out about the data set is measured. 
The study consisted of two parts. In the first part the user was asked to complete several tasks. 
This allowed the users to become familiar with the controls as wells as what the visualization was capable of. 
It also allows us to measure what information can be found.  In the second part the users explored the HIV virus on their own. 



\subsection{task 1}
Based on a description designed by a molecular bioligist and an illustrator, the first task was to investigate the capsid of the HIV virus.
The capsid encloses the genome (2 strands of RNA) along with different viral proteins. 
The capsid protein is able to form hexamers and pentamers by shifting slightly in structure, and folds to form two domains connected by a flexible linker: the N-terminal domain and C-terminal domain. 
The N-terminal domain is involved in forming the hexamers or pentamers, and the C-terminal domains are involved in dimer contacts between hexamers / pentamers. 
There are two $\alpha$-helices in the N-terminal that stabilize the hexamers and pentamers. 
As HIV is budding from an infected cell, the cellular enzyme cyclophilin A binds to the capsid. 
On the surface of the capsid protein there is a loop with several prolines, which is the site of binding of cyclophilin. 

The users were tasked with finding the following:

\begin{enumerate}
	\item A pentamer in the capsid
	\item C and N terminals
	\item Alpha helices
	\item Cyclophilin binding site
	\item A Methionine amino acid within the alpha helices 
\end{enumerate}

The users were given an in-depth description of the capsid and a structural representation of the Methionine amino acid. 
The task of finding the pentamer was added so the users would practice moving the camera around, as recognizing a pentamer was easier than actually finding one. 
If a user was not capable of finding a pentamer, then he simply continued. 
The Cyclophilin binding site was not an $\alpha$-helix or $\beta$-sheet, and as such received no special coloring (need to check just to make sure). 
This was to test whether or not the user could find a structure that was not explicitly marked. 
To find the Methionine amino acid, the user had to look for a sulfur atom; there was no other amino acid with a sulfur atom near it, though there is a second one in the protein. 
This is because the amino acids were not assigned a color. 
This task was designed so the user would interact with the visualization at the atomic level, i.e., to find a sulfur atom. 
If the user did not find the amino acid or realize that they needed to look for a sulfur atom, they were asked to find a sulfur atom instead.





\subsection{how evaluation was performed/measured}
In task 1 we were interested in whether or not they could complete the tasks, as well as what issues they ran into. 
Task 2 was a free exploration task.
What is important is the degree of exploration, as well as what the users were capable of finding or looking at, as the users were capable of focusing on many different object as well as on different levels.


\subsection{performance of users first iteration}
Two users participated in the first iteration. In task 1 neither found the pentamer. 
As mentioned before, this task was added simply for the user to get used to the controls. 
Both found the N and C terminals. 
Both found the Cyclophilin binding site, but only one found the alpha helix. 
One found the the amino acid, while the other found another sulfur atom.

In task 2 neither user interacted significantly with the visualization. This was likely due camera control issues. 
One of the participants had troubles getting the camera to point where he wanted in general, the other at the lower levels.

\subsection{feedback that was implemented into method}
Two issues were identified in the first iteration. 
The first problem was camera control. 
In order to use the camera when zoomed further in a certain degree of experience was required, otherwise the target could be easily overshot.
In order to fix this, we altered the camera controls so the user could slow down the camera movement significantly.
The other issue was the detection of the secondary structures. 
One of the users could not detect the secondary structures, the other could, but did not use our visualization.
We noticed that there were a several helices and sheets in the protein. 
This meant that the altering of the luminance might not seperate a helix from the surrounding area. 
Therefore, we altered the coloring of the secondary structures to be based on hue, and each secondary structure would receive its own hue.
This coloring is described in section [insert section number stuff].


\subsection{performance of users second iteration}
In the second iteration, none of the users had significant issues with the camera, though there was variation in degree of control.
One of the users was incapable of detecting the pentamer and mixed up the N and C terminals. 
As such only the the results for the other 4 users are described below. 
For the other 4 users the results were as follows:

\begin{enumerate}
	\item All 4 found a pentamer
	\item All 4 users could find the N and C terminals, though one mistook a subset of the C terminal as the entire C terminal. He had accidentally zoomed to far in and mistook a color of the secondary structure for the domain.
	\item 3 out of the 4 found the alpha helices
	\item All found the Cyclophilin binding site
	\item 2 found the Methionine. One of the other two found a sulfur atom, but believed it to belong to something else. The person who did not find the $\alpha$-helix was the one who also did not find the sulfur atom. He never zoomed to the atomic level.
\end{enumerate}

The actions of the users in the second task were extremely varied. 
Unlike the first iteration, all 4 users spent time exploring the virus. 
However, the parts they explored varied significantly. 
One tried to find the other amino acids in the capsid that had been mentioned in the description. 
He also took particular interest in the Cyclophilin binding site. 
Another user took interest in the membrane and the proteins near. 
The third looked at the atomic structure of proteins that were not part of the capsid. 
The forth, the user who did not detect the helices, did not explore the virus significantly.



\subsection{overall results}
The only problems with identifying structures came at the secondary structure and amino acid level. 
The amino acid level was significantly more difficult, as the amino acids were not visually represented. 
The users had to find it based on one atom, a search for which they had to arrive at themselves. 

A peculiar and interesting aspect was how little the users noticed the changing colors, yet still used the colors to identify the areas.
Every user that found the N and C terminals referred to them by color. 
Several referred to alpha helices by color. 
While all users noticed the changing colors when zooming to the atomic level, only one noticed it on all levels, while a second thought something odd was occuring on the secondary structure level, but couldn't be specific. 
This means that the visualization succeeded in creating a smooth transtion between the levels, and was still useful, despite the users not being aware of its support. 
Furthermore, the fact that most students were succesful at least up to the secondary structure level indicates that our visualization can be used on each level, though they did consider it to be difficult. 
They probably considered it to be more difficult than it actually is, because they were not aware that the visualization was supporting them.

The largest difference between the iterations was the degree of exploration in the second task. In the first task, neither user explored the HIV virus extensively. In contrast, the users from the second iteration explored the virus on different levels and areas. Likely this was affected significantly by the degree of control over the movement through the visualization. In the first iteration, the users had significant control issues which were absent in the second iteration due to changes. In both iterations no users got lost or confused by the visualization.

The users were also asked how useful they considered the visualization to be for their research, or what they could use it for. Only one user from the first iteration considered it useful for their research. This is in a sense not surprising. Most users worked on the level of molecular structure or protein interactions. Furthermore, while it may be possible to visualize an entire virus, a physical simulation of one is a different problem. This does not mean they considered it useless. They mentioned that they could use it in presenting their research, as well as for educating students.







%\subsection{feedback to implement into method}


%\subsection{stuff they'd like to see}
%- obviously they'd like everything.
%- cartoon representation
%- polarity etc.


%\subsection{uses and applications}
%
%
%We opted to perform a qualitative evaluation with XX biologists consisting of two blocks.
%In the first block, users had to identify a set of pre-defined structures across multiple levels of scale in the HIV model. 
%In the second block, users could freely explore the scene.
%In both blocks, users were encouraged to “think aloud”. 
%Sessions were observed by one to two study administrators, the screen was captured, and audio was recorded. 
%The session was concluded by a questionnaire and an audio-recorded semi-structured interview. 
%The task was provided by a professor of molecular biology and well-known illustrator of biological models. 
%Users were first provided by a description of the HIV capsid protein, which is the single protein building up the HIV capsid.
%Then they were asked to identify structures from this description in the HIV visualization, namely the capsid compartment itself, a special protein compound of the capsid, the two protein domains, secondary structures acting as binding sites, and a dedicated amino acid. 
%The study was conducted on a (laptop specification, screen, color calibration). 
%Users were sitting approximately ... cm from the screen, but were free to move. 
%Before performing the actual study task, users were demonstrated how to navigate in the scene, and how to switch on and off certain sub-compartments. 
%This was necessary so that all items were accessible without occlusions. 
%We decided to perform a qualitative evaluation as our visualization is new, and there is currently no visualization that allows the user to look at all levels in a similar manner, so we do not have a method of comparison.
%Our goal primarily was to see whether domain experts can identify the individual structures, whether this would be possible without color coding at all, and whether the view-dependent color assignment was irritating for them. 
%
%Users
%The users were molecular biology students. As such, they had some but limited knowledge of the field [tbd may be variation]. 
%As such, there needed to be an explanation of what they were looking for. The students ranged from x to y years studying.
%
%Results
%-	How many students found the different targets
%-	Insights
%-	Probably need table of different types of insights.
%-	Insights per minute  (ipm)
%-	Answer to the questions we pose (table?)
%-	People used
%-	Number of people used
%-	Describe type of study
%-	Describe what this kind of study is.
%-	Reference other (similar) studies
%-	Argue why 
%o	No baseline
%o	No quantifiability (x in y seconds)
%o	Want to measure usability


\section{Conclusion}
The work presented here is a method that is capable of rendering a cell-like structure on different levels in a coherent and cohesive manner using color. 
The user study performed with this software shows that users can find information in an HIV virus dataset on each level. 
The coloring scheme is capable of showing structures on each level in a visually distinct manner.



\subsection{limitations}
There are still two basic limitations to our coloring scheme. 
The first is information on two different levels that are very close to each other, for example the amino acids and atoms. 
Amino acids vary significantly in size and complexity, however some consist out of just several carbon atoms with even less other atom types, except for hydrogen. 
Serine for example has only of 4 carbon atoms. This means the user will be approximately as far away from a molecule when he wants to see the atoms or amino acid information. 
The second problems is the variety of information. For example, due to polarity, the electric charge may vary across a molecule. 
A researcher may want to see this information instead of amino acid or atomic information for example.
This means that there are several paths can be taken when zooming in.
The last problem is alternative represtations, such as cartoon representations of the secondary structure of proteins. 
Several users expressed a desire for alternative representations that they were more familiar with. 
However, there can be some difficulty when using them. The cartoon representation for example has a lot of area which can be seen through. 
If two proteins are one behind the other, then they can be hard to tell apart.
- need to ask mathieu on "overflow of compartments"


\subsection{future work}
There are several points that can be addressed in the future. The most obvious is to overcome the two basic limitations mentioned above. 
The users also expressed interest in interacting with the visualization. 
Structures such as the capsid are structures that consist out of numerous proteins. 
The users wanted to be able highlight individual proteins or sections. 
It might also be possible to couple this action with alternative representations for proteins, such as the cartoon representation.
Finally, camera control can be adapted to the visualization. 
Currently, the camera is controlled simply by inputing the desired direction of movement. 
Alternate controls, such as tying the camera to a protein or structure could be added.
This would allow the user easier inspection of proteins or protein structures by making it easier for him to rotate around or follow the surface of an object.



%% if specified like this the section will be committed in review mode
\acknowledgments{
The authors wish to thank A, B, C. This work was supported in part by
a grant from XYZ.}

\bibliographystyle{abbrv}
%%use following if all content of bibtex file should be shown
%\nocite{*}
\bibliography{Chameleon}
\end{document}
